{"title":"Análisis de correlación","markdown":{"yaml":{"title":"Análisis de correlación"},"headingText":"1. En R","containsRefs":false,"markdown":"\n\n```{=html}\n<style>\nbody {\ntext-align: justify}\n</style>\n```\n\n```{r setup, include=FALSE, message=FALSE, warning=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,\n                      fig.align = 'center', # Para que los gráficos de los comandos estén centrados en la página\n                      out.width = '60%') # Para modificar el tamaño de los gráficos (en este caso hacerlos algo más pequeños)\n```\n\n```{r include=FALSE}\nlibrary(tidyverse)\nlibrary(pacman)\nsource(\"00_datos/source.R\")\n```\n\n\nLos análisis de correlación buscan averiguar si existe relación entre dos variables continuas.\n\n### **Covarianza:**\n\n``` r\ncov(datos$var1, datos$var2)\n```\n\nEj. Se quiere comprobar la relación entre en índice de corrupción de un país (*cpi*, donde 0=más corrupto; 10=menos corrupto) y el índice de desarrollo humano (*hdi*, donde 0=más bajo; 1=más alto).\n\n```{r message=FALSE, warning=FALSE}\ncov(data$cpi, data$hdi)\n```\n\n### **Correlación de Pearson:**\n\nLa función para calcular la correlación es `cor()` *(funciona igual que el comando cov)*. Sin embargo, para poder interpretar más adecuadamente los resultados de la correlación conviene realizar un test para comprobar si dicha correlación es estadísticamente significativa. Las hipótesis de este test son:\n\n-   H~0~= la correlación es igual a 0, así que no hay relación\n-   H~1~= la correlación es significativamente distinta de 0\n\n``` r\ncor.test(datos$var1, datos$var2)\n```\n\nEj.:\n\n```{r}\ncor(data$cpi, data$hdi) # devuelve el valor de la correlación\ncor.test(data$cpi, data$hdi) # hace un test\n```\n\nLos resultados muestran que la correlación entre ambas variables tiene un valor de 0,72. El test arroja tres resultados:\n\n-   t=13,186 --\\> t\\>3,26\n-   p\\<2.2e-16 --\\> p\\<0,001\n-   IC= \\[0.6406049, 0.7902298\\]\n\nBasándonos en estos resultados, podemos rechazar la hipótesis nula y afirmar que la correlación es significativamente distinta de cero para un nivel de confianza del 99,9%\n\n### **Correlación de más de dos variables a la vez:**\n\n```{r include=FALSE}\n#Para estos ejemplos se usa la base de datos mtcars, que viene incluída con R.\nattach(mtcars)\nData <- mtcars\n```\n\n1.  Correlación entre todas las variables del dataset. Es fundamental que sean TODAS numéricas.\n\n```{r}\ncor(Data)\n```\n\n2.  Si solo se quiere la relación entre varias variables concretas, se puede hacer de forma manual del siguiente modo:\n\n```{r}\nx <- Data[c(1:3, 5)]\ny <- Data[6:8]\ncor(x, y)\n```\n\n### **Visualización de correlaciones:**\n\nAdemás de usar funciones de cálculo, suele ser de gran ayuda visualizar las correlaciones entre variables gráficamente.\n\n-   Nube de puntos (dos variables):\n\n```{r}\nplot(data$cpi, data$hdi, #Los datos que se van a usar para hacer el gráfico\n     main = \"CPI/HDI\", #El título del gráfico\n     xlab = \"Corruption perception index\", #El texto del eje X\n     ylab = \"Human development index\", #El texto del eje Y\n     pch = 18) #Establece la forma de los puntos (triángulos, círculos, x...)\n```\n\n-   Correlaciones para más de dos variables a la vez:\n\n``` r\nlibrary(corrgram)\ncorrgram(datos)\n```\n\nEj.:\n\n```{r include=FALSE}\nlibrary(corrgram)\n```\n\n```{r}\ncorrgram(Data)\n```\n\n*El comando cuenta con numerosas argumentos extra para modificar y mejorar la visualización del gráfico final (ver ?corrgram). P. ej.:*\n\n```{r}\ncorrgram(Data, order=TRUE, lower.panel=NULL,\n         upper.panel=panel.pie, text.panel=panel.txt,\n         main=\"Car Milage Data in PC2/PC1 Order\")\n```\n\n------------------------------------------------------------------------\n\n## 2. Teoría\n\nSi queremos analizar la dependencia entre dos **variables continuas** XX e YY, no podemos estudiar sus distribuciones por separado, sino que debemos hacerlo de manera conjunta. Para ello, definimos una variable estadística bidimensional (X,Y)(X,Y), cuyos valores serán todos los pares formados por los valores de las variables XX e YY.\n\nLa representación gráfica más utilizada para examinar la relación entre dos variables numéricas es el diagrama de dispersión. Este consiste en representar, sobre un plano cartesiano, los puntos correspondientes a los pares de valores ($x_{i}$, $y_{i}$) de la variable bidimensional. Estas nubes de puntos nos permiten visualizar el tipo de relación existente entre las variables (lineal, exponencial, positiva, negativa, etc.). Si además queremos cuantificar la intensidad de dicha relación, es necesario recurrir a medidas estadísticas, como la covarianza muestral o el coeficiente de correlación.\n\nLa **covarianza** de una variable bidimensional se obtiene promediando los productos de las desviaciones de cada valor con respecto a las medias de XX e YY. Una vez calculadas las medias, podemos calcular la covarianza siguiendo la siguiente fórmula:\n\n$$cov_{x,y} = \\frac{\\sum\\limits_{i=1}^{n}{(x_i-\\overline{x}) \\cdot (y_i-\\overline{y})} }{n-1}$$\n\nEl valor de la covarianza nos indica lo siguiente:\n\n-   Si cov\\>0, relación lineal creciente entre las variables\n-   Si cov\\<0, relación lineal decreciente entre las variables\n-   Si cov=0, no existe relación lineal entre las variables\n\nEl problema de esta medida es que depende de las unidades. Imaginemos que las unidades de la variable x son *cm* y las de la variable y son *gr*. En este caso, las unidades de la covarianza serán *cm × gr*, y si cambiamos la escala de las variables, la covarianza también cambiará. Esto hace que el valor de la covarianza sea difícil de interpretar. (la variazna es la distancia de los puntos hacia los ejes. La covarianza es la distancia de los puntos entre sí)\n\nPara evitar este problema, es recomendable utilizar una medida normalizada, como el coeficiente de **correlación de Pearson**, que toma valores entre -1 y 1, donde:\n\n-   ρ = 1 indica una relación lineal perfecta y positiva\n-   ρ = -1 indica una relación lineal perfecta y negativa\n-   ρ = 0 indica ausencia de relación entre las variables\n\n$$\\rho = \\frac{\\text{cov}(X,Y)}{\\sigma_x \\sigma_y}$$\n\n**Correlación no implica causalidad**\n\nLa correlación entre dos variables v1 y v2 puede deberse a:\n\n-   Relación causal: V1 es la causa, V2 el efecto (o viceversa)\n-   Azar\n-   Variable interviniente (confounding factor):\n    -   [Relaciones espúreas](http://www.tylervigen.com/spurious-correlations): es una correlación aparente entre dos variables que en realidad es causada por la influencia de una tercera variable, conocida como variable de confusión. Aunque las dos variables parecen estar relacionadas, su relación no es causal.\n    -   [Paradoja de Simpson](https://upload.wikimedia.org/wikipedia/commons/f/fb/Simpsons_paradox_-_animation.gif): ocurre cuando una tendencia observada en varios grupos desaparece o se invierte al combinar los datos de esos grupos. Esto sucede debido a la influencia de una variable oculta o de confusión que afecta la interpretación de la relación entre las variables. Aquí tenéis un [ejemplo muy conocido](https://rpubs.com/dawnwp/1081716).\n\n------------------------------------------------------------------------\n","srcMarkdownNoYaml":"\n\n```{=html}\n<style>\nbody {\ntext-align: justify}\n</style>\n```\n\n```{r setup, include=FALSE, message=FALSE, warning=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,\n                      fig.align = 'center', # Para que los gráficos de los comandos estén centrados en la página\n                      out.width = '60%') # Para modificar el tamaño de los gráficos (en este caso hacerlos algo más pequeños)\n```\n\n```{r include=FALSE}\nlibrary(tidyverse)\nlibrary(pacman)\nsource(\"00_datos/source.R\")\n```\n\n## 1. En R\n\nLos análisis de correlación buscan averiguar si existe relación entre dos variables continuas.\n\n### **Covarianza:**\n\n``` r\ncov(datos$var1, datos$var2)\n```\n\nEj. Se quiere comprobar la relación entre en índice de corrupción de un país (*cpi*, donde 0=más corrupto; 10=menos corrupto) y el índice de desarrollo humano (*hdi*, donde 0=más bajo; 1=más alto).\n\n```{r message=FALSE, warning=FALSE}\ncov(data$cpi, data$hdi)\n```\n\n### **Correlación de Pearson:**\n\nLa función para calcular la correlación es `cor()` *(funciona igual que el comando cov)*. Sin embargo, para poder interpretar más adecuadamente los resultados de la correlación conviene realizar un test para comprobar si dicha correlación es estadísticamente significativa. Las hipótesis de este test son:\n\n-   H~0~= la correlación es igual a 0, así que no hay relación\n-   H~1~= la correlación es significativamente distinta de 0\n\n``` r\ncor.test(datos$var1, datos$var2)\n```\n\nEj.:\n\n```{r}\ncor(data$cpi, data$hdi) # devuelve el valor de la correlación\ncor.test(data$cpi, data$hdi) # hace un test\n```\n\nLos resultados muestran que la correlación entre ambas variables tiene un valor de 0,72. El test arroja tres resultados:\n\n-   t=13,186 --\\> t\\>3,26\n-   p\\<2.2e-16 --\\> p\\<0,001\n-   IC= \\[0.6406049, 0.7902298\\]\n\nBasándonos en estos resultados, podemos rechazar la hipótesis nula y afirmar que la correlación es significativamente distinta de cero para un nivel de confianza del 99,9%\n\n### **Correlación de más de dos variables a la vez:**\n\n```{r include=FALSE}\n#Para estos ejemplos se usa la base de datos mtcars, que viene incluída con R.\nattach(mtcars)\nData <- mtcars\n```\n\n1.  Correlación entre todas las variables del dataset. Es fundamental que sean TODAS numéricas.\n\n```{r}\ncor(Data)\n```\n\n2.  Si solo se quiere la relación entre varias variables concretas, se puede hacer de forma manual del siguiente modo:\n\n```{r}\nx <- Data[c(1:3, 5)]\ny <- Data[6:8]\ncor(x, y)\n```\n\n### **Visualización de correlaciones:**\n\nAdemás de usar funciones de cálculo, suele ser de gran ayuda visualizar las correlaciones entre variables gráficamente.\n\n-   Nube de puntos (dos variables):\n\n```{r}\nplot(data$cpi, data$hdi, #Los datos que se van a usar para hacer el gráfico\n     main = \"CPI/HDI\", #El título del gráfico\n     xlab = \"Corruption perception index\", #El texto del eje X\n     ylab = \"Human development index\", #El texto del eje Y\n     pch = 18) #Establece la forma de los puntos (triángulos, círculos, x...)\n```\n\n-   Correlaciones para más de dos variables a la vez:\n\n``` r\nlibrary(corrgram)\ncorrgram(datos)\n```\n\nEj.:\n\n```{r include=FALSE}\nlibrary(corrgram)\n```\n\n```{r}\ncorrgram(Data)\n```\n\n*El comando cuenta con numerosas argumentos extra para modificar y mejorar la visualización del gráfico final (ver ?corrgram). P. ej.:*\n\n```{r}\ncorrgram(Data, order=TRUE, lower.panel=NULL,\n         upper.panel=panel.pie, text.panel=panel.txt,\n         main=\"Car Milage Data in PC2/PC1 Order\")\n```\n\n------------------------------------------------------------------------\n\n## 2. Teoría\n\nSi queremos analizar la dependencia entre dos **variables continuas** XX e YY, no podemos estudiar sus distribuciones por separado, sino que debemos hacerlo de manera conjunta. Para ello, definimos una variable estadística bidimensional (X,Y)(X,Y), cuyos valores serán todos los pares formados por los valores de las variables XX e YY.\n\nLa representación gráfica más utilizada para examinar la relación entre dos variables numéricas es el diagrama de dispersión. Este consiste en representar, sobre un plano cartesiano, los puntos correspondientes a los pares de valores ($x_{i}$, $y_{i}$) de la variable bidimensional. Estas nubes de puntos nos permiten visualizar el tipo de relación existente entre las variables (lineal, exponencial, positiva, negativa, etc.). Si además queremos cuantificar la intensidad de dicha relación, es necesario recurrir a medidas estadísticas, como la covarianza muestral o el coeficiente de correlación.\n\nLa **covarianza** de una variable bidimensional se obtiene promediando los productos de las desviaciones de cada valor con respecto a las medias de XX e YY. Una vez calculadas las medias, podemos calcular la covarianza siguiendo la siguiente fórmula:\n\n$$cov_{x,y} = \\frac{\\sum\\limits_{i=1}^{n}{(x_i-\\overline{x}) \\cdot (y_i-\\overline{y})} }{n-1}$$\n\nEl valor de la covarianza nos indica lo siguiente:\n\n-   Si cov\\>0, relación lineal creciente entre las variables\n-   Si cov\\<0, relación lineal decreciente entre las variables\n-   Si cov=0, no existe relación lineal entre las variables\n\nEl problema de esta medida es que depende de las unidades. Imaginemos que las unidades de la variable x son *cm* y las de la variable y son *gr*. En este caso, las unidades de la covarianza serán *cm × gr*, y si cambiamos la escala de las variables, la covarianza también cambiará. Esto hace que el valor de la covarianza sea difícil de interpretar. (la variazna es la distancia de los puntos hacia los ejes. La covarianza es la distancia de los puntos entre sí)\n\nPara evitar este problema, es recomendable utilizar una medida normalizada, como el coeficiente de **correlación de Pearson**, que toma valores entre -1 y 1, donde:\n\n-   ρ = 1 indica una relación lineal perfecta y positiva\n-   ρ = -1 indica una relación lineal perfecta y negativa\n-   ρ = 0 indica ausencia de relación entre las variables\n\n$$\\rho = \\frac{\\text{cov}(X,Y)}{\\sigma_x \\sigma_y}$$\n\n**Correlación no implica causalidad**\n\nLa correlación entre dos variables v1 y v2 puede deberse a:\n\n-   Relación causal: V1 es la causa, V2 el efecto (o viceversa)\n-   Azar\n-   Variable interviniente (confounding factor):\n    -   [Relaciones espúreas](http://www.tylervigen.com/spurious-correlations): es una correlación aparente entre dos variables que en realidad es causada por la influencia de una tercera variable, conocida como variable de confusión. Aunque las dos variables parecen estar relacionadas, su relación no es causal.\n    -   [Paradoja de Simpson](https://upload.wikimedia.org/wikipedia/commons/f/fb/Simpsons_paradox_-_animation.gif): ocurre cuando una tendencia observada en varios grupos desaparece o se invierte al combinar los datos de esos grupos. Esto sucede debido a la influencia de una variable oculta o de confusión que afecta la interpretación de la relación entre las variables. Aquí tenéis un [ejemplo muy conocido](https://rpubs.com/dawnwp/1081716).\n\n------------------------------------------------------------------------\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"include-in-header":{"text":"<style>\n/* Estilos para todo el documento */\nbody {\n  text-align: justify;\n}\n\n/* Estilos específicos para la tabla de contenidos */\n.toc-actions, .toc .nav, .toc .nav > li > a {\n  text-align: left !important;\n}\n</style>\n"},"output-file":"42_correlacion.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","knitr":{"opts_chunk":{"echo":true,"message":false,"warning":false,"fig.align":"center","out.width":"60%"}},"editor":"visual","theme":{"light":"flatly","dark":"darkly"},"toc-title":"Contenido","title":"Análisis de correlación"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}