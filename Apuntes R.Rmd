---
title: "Apuntes R"
clean: T
output:
  html_document:
    theme: default
    css: style.css
lang: es
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      fig.align = 'center', # Para que los gr√°ficos de los comandos est√©n centrados en la p√°gina
                      out.width = '60%') # Para modificar el tama√±o de los gr√°ficos (en este caso hacerlos algo m√°s peque√±os)
```


```{r cosas previas include=FALSE}
setwd("C:/Users/Lenovo/OneDrive/Escritorio/Apuntes R")
library(tidyverse)
library(pacman)
source("00_datos/source.R")
```


# {.tabset .tabset-fade .tabset-pills}
## Introducci√≥n
#### R Studio

<center>
![Ventanas de R Studio](01_img/ventanas_rstudio.png)
</center>

- Editor de c√≥digo: ficheros donde se escribe el c√≥digo. Elemento clave para la reproducibilidad.
- Consola: muestra los resultados del c√≥digo ejecutado y permite ejecutar c√≥digo de forma r√°pida (poco recomendable excepto para pruebas y mirar cosas muy concretas y r√°pidas) 
- Ventana de ambiente: muestra los objetos almacenados
- Ventana de ficheros/gr√°ficos‚Ä¶
  - Permite visualizar resultados del trabajo: gr√°ficos, html‚Ä¶
  - Encontrar ficheros
  - Ver detalles de los paquetes empleados, etc.

Existen diversos formatos para escribir c√≥digo en R, siendo dos de los m√°s destacados los siguientes:

- **Script**: √∫til si solo se quiere escribir c√≥digo.
- **RMarkdown**: m√°s util si se quieren a√±adir anotaciones de texto frecuentes. Adem√°s, cuenta con numerosas opciones extra, como a√±adir imagenes, tablas o guardar los documentos en formato pdf o html, entre otras funciones.

#### Instalar paquetes
Los paquetes son un conjunto de c√≥digo, datos y documentaci√≥n que permiten implementar funciones predefinidas extra.

**R b√°sico**:

Para instalar un paquete, se puede hacer busc√°ndola en la pesta√±a`Install` dentro de la pesta√±a `Packages` (esquina inferior derecha de la pantalla).

Tambi√©n se puede instalar usando el siguiente comando: `install.packages("nombre_librer√≠a")`

Una vez instalada, se abre usando el comando: `library("nombre_librer√≠a")`

IMPORTANTE: las librer√≠as deben abrise siempre que se usen (no con cada comando que se use, sino con cada sesi√≥n de R que se abra), pero solo se instalan una vez.

**Librer√≠a pacman**:

1. Instalar la librer√≠a pacman.
2. Abrir la librer√≠a.
3. Cuando se vaya a abrir una nueva librer√≠a, en lugar de usar el comando `library("nombre_librer√≠a")` se usa `p_load("nombre_librer√≠a")`
    - La ventaja de este comando es que, en caso de que no est√© instalada la librer√≠a, se descargar√° y abrir√° directamenta.

**Paquetes de GitHub**:

Tanto `install.packages` como `p_load` sirven √∫nicamente para paquetes que est√©n dentro de CRAN. Para instalar los que est√©n en GitHub se debe usar el comando `devtools::install_github("librar√≠a")`, que pertenece a la librer√≠a `devtools`.



#### Recomendaciones
Al comenzar un nuevo trabajo en R, conviene crear un proyecto nuevo en el que se quiera trabajara, y mantener este ordenado. Tambi√©n es recomendable guardar todos los c√≥digos de forma estructurada, de modo que tanto otras personas como tu yo del futuro puedan saber para qu√© sirven cada una de las cosas que se han a√±adido.


#### Atajos

- A√±adir un **pipe** (%>%): ctrl + shift + m
- A√±adir una almoadilla a la l√≠nea de c√≥digo sobre la que se est√©: ctrl + shift + c

**En RMarkdown**

- A√±adir un nuevo chunl de r: ctrl + alt + i

**En un script**

- Crear nuevas secciones dentro del documento: ctrl + shift + r

***
## RMarkdown {.tabset .tabset-fade .tabset-pills}
### 1. Elementos b√°sicos

**Yalm**

Se escribe al comienzo del documento, y establece las caracter√≠sticas b√°sicas de este y como se va a guardar.

 <pre><code>---
 title: "El t√≠tulo del documento"
 subtitle: "El subt√≠tulo"
 date: "Fecha"
 author: "Autor"
 output:
  html_document: #tambi√©n se puede guardar como pdf o word, as√≠ saca una p√°gina web
    theme: united #es el tema del documento, hay diferentes
    toc: true #para crear una tabla de contenido
 ---</code></pre>

Muchos de estos elementos son opcionales, y se pueden a√±adir m√°s.

Ejemplos de temas que se pueden utilizar para el documento: https://rpubs.com/ranydc/rmarkdown_themes

**Chunks**

Para escribir los c√≥digos de R y que estos se puedan ejecutar, se debe a√±adir un chunk. Se puede hacer manualmente o mediante el atajo Ctrl + Alt + I.

Para ejecutar el c√≥dico que se escriba, se puede pulsar el tri√°ngulo verde de la esquina superior derecha (del chunk), la opci√≥n Run de la esquina de la pesta√±a del rmd, o usando Ctrl+Enter.

Dentro de los chunks, se pueden establecer diferentes opciones para que no se muestre el c√≥digo en el documento final pero se ejecute igualmente, no se muestren los errores... Estos ajustes se puedes escribir como comandos dentro de {r} o en la rueda de opciones que aparece a la derecha de cada chunk.

Los chunks de R adem√°s permiten ejecutar todo el contenido de los chunks empleados con anterioridad, lo que puede resultar muy √∫til en el casdo de cometer errores que nedesitar resetear todo el trabajo realizado hasta el momento. Para ello, se debe seleccrionar la segunda opci√≥n que aparece en la esquina superior derecha del chunk (entre la rueda y el tri√°ngulo verde).

**Encabezados**

Sirven para delimitar los diferentes apartados y subapartados de los documentos. Se crean con las # (en una nueva l√≠nea se escribir√≠a: # Encabezado de nivel 1). El espacio entre la almohadilla y el texto es imprescindible. Si en lugar de escribir una √∫nica # se ponen 2, 3... o 6, se van creando subniveles de encabezados (un mayor n√∫mero de almohadillas indica un nivel inferior de encabezado).

**Espacio entre l√≠neas**

Si se quiere a√±adir un salto de l√≠nea, se debe dejar una l√≠nea de c√≥digo vac√≠a entre los dos textos que se pretenden separar. Si simplemente se escribe en la siguiente l√≠nea, se compliar√° todo como parte del mismo p√°rrafo.

**Compilar el documento**

Se selecciona la opci√≥n Knit, lo que genrar√° un documento HTML/PDF con todo el contenido y los resultados.

***
### 2. Opciones de texto y otros elementos
**Formatos de texto:**

* \*\*Texto en negrita** = **Texto en negrita** (los  asteriscos se pueden sustituir por _)
* \*Texto en cursiva* = *Texto en cursiva*
* \*\*\*Texto en negrita y cursiva*** = ***Texto en negrita y cursiva***
* \`C√≥digo subrayado\` = `C√≥digo subrayado`
* Sub√≠ndice: 3\~2~ = 3~2~
* Super√≠ndice: 3\^2^ = 3^2^ 

**Listas:**

Para las listas de puntos, se escriben al comienzo de la l√≠nea de c√≥digo y seguido de un espacio antes del texto un asterisco (*) o un gui√≥n (-). Adem√°s, si en la siguiente l√≠nea se a√±ade espacio tambi√©n antes del s√≠mbolo, se crear√° una sublista:

- Elemento 1
  - Elemento 2

Tambi√©n se pueden hacer listas con n√∫meros y letras: 1. 1)  A. i. etc. 


**Ecuaciones**

Se escribe el texto de la ecuaci√≥n entre dos s√≠mbolos del dolar. Ej.: \$E=mc^{2}\$ = $E=mc^{2}$

Si se quiere que la ecuaci√≥n est√© en un bloque a parte en lugar de dentro del texto, se a√±aden dos s√≠mbolos del dolar para abrir y cerrar la ecuaci√≥n: $$E=mc^{2}$$


**Hiperv√≠nculos**

El texto para el que se quiere el hiperv√≠nculo se escribe entre corchetes, y a continuaci√≥n (sin dejar espacios) se escribe entre par√©ntesis el enlace a la p√°gina para la que se quiere el hiperv√≠nculo. Ej.: \[Texto del hiperv√≠nculo]\(paginaweb.com)

**A√±adir im√°genes**

Hay varias opciones para insertar una imagen en el texto. Por ejemplo, puedes guardarla previamente en el directorio de trabajo (o en el proyecto que hayas creado). Una vez la tienes en tu directorio, puedes usar esta l√≠nea de c√≥digo para introducirla en el documento final: `![t√≠tulo de la imagen](path-to-image-here)`. Adem√°s, se puede combinar con _center_ para centrar la imagen en el output, y con _width_ para ajustar el tama√±o.

```r
<center>
![T√≠tulo de la imagen](mi_imagen.png){width=350px}
</center>
```

Otra manera sencilla de controlar el tama√±o es usando porcentajes: `{width=10%}`

Una alternativa bastante usada, por ejemplo, es usar _include_graphics_ para controlar el ancho y alto de la imagen a√±adiendo como opci√≥n dentro de {r} lo siguiente: `out.width = "100px", out.height="300px"`

```r 
knitr::include_graphics("mi_imagen.png")
```

Tambi√©n tenemos la opci√≥n de introducir una imagen directamente desde la web (es decir, sin descargarla previamente). Primero, creamos una variable con la direcci√≥n url. Una vez creada la variable, se a√±ade igual que una im√°gen guardada en el directorio:

```r
nombre_imagen<-"https://ejemplo_imagen.jpg" 
```


**L√≠neas horizontales**

Se a√±aden escribiendo en una l√≠nea vac√≠a *** o ---. El resultado es:

***

Existen muchas otras opciones dentro del RMarkdown, como incluir tablas, citas, referencias... En el [enlace](https://rstudio.github.io/cheatsheets/html/rmarkdown.html) se puede encontrar informaci√≥n extra, aunque es solo un ejemplo de p√°gina sobre RMarkdown.

***
### 3. √çndices y tablas de contenido {.tabset .tabset-fade .tabset-pills}
#### 2.1. √çndice como lista al comienzo del documento

Los √≠ndices se crean a partir de los t√≠tulos (#). Se puede especificar el n√∫mero de niveles que se quieren incluir gracias a la opcion`toc_depth`:

<pre><code> ---
title: "El t√≠tulo del documento"
output:
  html_document:
    toc: true
    toc_depth: 3 #En este caso se incluir√≠an los tres primeros niveles del t√≠tulos (hasta ###)
--- </code></pre>

***
#### 2.2. √çndice a la izquierda del documento

**Tabla de contenido despegable**

Para poder hacer una tabla de contenido despegable, se debe crear un css personalizado:

**√çndice personalizable en RMarkdown**

Para crear un √≠ndice (TOC - Table of Contents) personalizable en RMarkdown que sea flotante y se pueda ocultar/mostrar, necesitamos a√±adir c√≥digo CSS y JavaScript. Aqu√≠ te explico paso a paso c√≥mo hacerlo.

**1. C√≥digo CSS necesario**

Primero, necesitas a√±adir este bloque de c√≥digo CSS al inicio de tu documento. Este c√≥digo dar√° estilo al √≠ndice y crear√° la funcionalidad de mostrar/ocultar:

<pre><code>```{css, echo=FALSE}
hr {
  border: none;
  border-top: 3px solid #bbb;
  margin: 1em 0;
}
 #TOC {
  position: fixed;
  left: 0;
  top: 0;
  width: 300px;
  height: 100%;
  overflow-y: auto;
  background: #f8f8f8;
  border-right: 1px solid #e7e7e7;
  padding: 20px;
  transition: left 0.3s ease;
}
 #TOC.hidden {
  left: -300px;
}
 #toggle-toc {
  position: fixed;
  top: 5px;
  left: 5px;
  z-index: 1000;
  background: #f8f8f8;
  border: 1px solid #e7e7e7;
  padding: 5px 10px;
  cursor: pointer;
}
.main-content {
  transition: margin-left 0.3s ease;
  margin-left: 200px;
}
.main-content.toc-hidden {
  margin-left: 150px;
}
@media (max-width: 767px) {
  .main-content {
    margin-left: 0;
  }
}
```</code></pre>

**2. C√≥digo JavaScript necesario**

Luego, necesitas a√±adir este bloque de c√≥digo JavaScript que proporcionar√° la funcionalidad interactiva:

<pre><code>```{js, echo=FALSE}
$(document).ready(function() {
  var toc = $('#TOC');
  var toggle = $('<button id="toggle-toc">‚ò∞</button>');
  var mainContent = $('body > .main-container');
  $('body').prepend(toggle);
  mainContent.addClass('main-content');
  toggle.click(function() {
    toc.toggleClass('hidden');
    mainContent.toggleClass('toc-hidden');
  });
  // Inicializar el estado en pantallas peque√±as
  if ($(window).width() <= 767) {
    toc.addClass('hidden');
    mainContent.addClass('toc-hidden');
  }
});
```</code></pre>

**3. Configuraci√≥n del YAML**

Adem√°s, aseg√∫rate de que tu encabezado YAML incluya la opci√≥n de tabla de contenidos:

 <pre><code>---
title: "Tu t√≠tulo"
output: 
  html_document:
    toc: true
    toc_float: true
 ---</code></pre>

**4. C√≥mo funciona**

Este c√≥digo crear√°:

* Un √≠ndice flotante en el lado izquierdo de la p√°gina

* Un bot√≥n (‚ò∞) en la esquina superior izquierda para mostrar/ocultar el √≠ndice

* El √≠ndice se ocultar√° autom√°ticamente en dispositivos m√≥viles

* Transiciones suaves al mostrar/ocultar el √≠ndice

**Nota:** El c√≥digo CSS y JavaScript debe colocarse al principio del documento, despu√©s del encabezado YAML.

**Personalizaci√≥n**

Puedes personalizar el aspecto modificando los valores en el c√≥digo CSS:

* Cambia `width: 300px` en `#TOC` para ajustar el ancho del √≠ndice

* Modifica `background: #f8f8f8` para cambiar el color de fondo

* Ajusta `margin-left` en `.main-content` para cambiar el espaciado del contenido principal

***
#### 2.3. √çndice por pesta√±as
1. En el yalm no se escribe el toc: true
2. Tras el primer t√≠tulo (que se puede dejar en blanco escribiendo √∫nicamente la #) se escribe el siguiente comando `{.tabset .tabset-fade .tabset-pills}`.
3. Esta opci√≥n se puede repetir para los sucesivos subniveles de t√≠tulos, creando nuevas pesta√±as dentro de cada pesta√±a (como en este archivo).

***
#### 2.4. N√∫meros de secci√≥n
En lugar de a√±adir a mano los n√∫meros delante de cada t√≠tulo (1.2. Subtitulo), estos se pueden a√±adir autom√°ticamente gracias a la siguiente opci√≥n:

<pre><code>---
title: "El t√≠tulo del documento"
output:
  html_document:
    toc: true
    number_sections: true
---</code></pre>

Si se utiliza esta opci√≥n, hay que comenzar los t√≠tulos por el primer nivel, porque si no en el segundo apareceran como 0.1 0.2 ...

***
### 4. Otras cosas RMarkdown

* Para escribir c√≥digo de R sin que se ejecute (pero mostr√°ndolo en el html), se borran las llaves que rodean la r del chunk:
  + C√≥digo que se ejecuta:

<pre><code>```{r}
Aqu√≠ ir√≠a el c√≥digo
```</code></pre>

  + C√≥digo que no se ejecuta:

<pre><code>```r
Aqu√≠ ir√≠a el c√≥digo
```</code></pre>

* **Crear √≠ndices a mano** (lista con hiperv√≠nculos)
  1) Junto a un t√≠tulo (para cualquier nivel de #), se escribe: {#nombre-secci√≥n}
  2) Donde se quiera crear el √≠ndice se pone el siguiente texto: [Nombre de la secci√≥n] (#nombre-secci√≥n) *Importante: no se debe dejar ning√∫n espacio entre el corchete y el par√©ntesis*.


***
## Flujos de trabajo
El **directorio** de trabajo es el lugar donde R busca los archivos que le pides que cargue, y donde guardar√° los archivos que generes.

Para trabajar dentro de una carpeta del ordenador exiten dos opciones:
- Crear un nuevo proyecto y trabajar desde ah√≠.
- Establecer manualmente el directorio:
```r
setwd("direcci√≥n de la carpeta en el ordenador")
```

Para consultar los ficheros que hay dentro de nuestro directorio de trabajo podemos usar la funci√≥n `dir()`
```r
dis()
```


### Source

Extraer el c√≥digo a un script de R:

```r
knitr::purl("nombre_archivo.Rmd")
```

Ejecutar todo el c√≥digo de un script sin mostrarlo:

```r
source("nombre_archivo.R")
```

Se escribe al principio del RMarkdown (o del script) para que ejecute directamente un script sin mostrar todo el c√≥digo (en el environment) (importa el c√≥digo sin mostrarlo todo).

Por ejemplo, puedes tener un script solo con la limpieza de la base de datos, y para que no sea tan largo y lioso el documento, ejecutarlo directamente y en el nuevo RM comenzar directamente con el an√°lisis.

***
## Operaciones b√°sicas  {.tabset .tabset-fade .tabset-pills}
### 1. Operaciones num√©ricas

- Suma, resta, multiplicaci√≥n, divisi√≥n, exponencial...
- Cuadrado (sqrt) y logaritmos (log)
- Absoluto:
```{r}
abs(-1.4)
```
- Redondear: 
```{r}
round(1.234, 2) #El segundo n√∫mero indica el n√∫mero de decimales al que se redondear√°.
```

***
### 2. Edici√≥n de caracteres (texto)

- Uni√≥n de caracteres:
```{r}
paste("Hola", "mundo", sep = " ")
paste0("Hola", "mundo")
```
- Seleccionar una parte del texto:
```{r}
substring("Nombre: Marga", first = 7, last = 11)
```
- Pasar un texto a min√∫sculas:
```{r}
tolower("Hola, soy Marga")
```
- Pasar un texto may√∫sculas:
```{r}
toupper("Hola, soy Marga")
```
- Contar el n√∫mero de caracteres (tambi√©n espacios y s√≠mbolos, no solo letras):
```{r}
nchar("Hola, mundo!")
```

***
### 3. Operadores l√≥gicos y relacionales
**Operadores l√≥gicos:**

-   `!` NOT (lo opuesto)
-   `&` AND
-   `|` OR

**Operadores relacionales:**

-   `==` igual
-   `!=` distinto
-   `>` mayor que
-   `>=` mayor o igual que
-   `<=`menor o igual que
-   `<` menor que

### 4. Operaciones con vectores
Un vector es una secuencia de elementos del mismo tipo (num√©rico, car√°cter, l√≥gico, etc.). Se puede asimilar a una variable.

- Ver de qu√© tipo es el vector: `class()`
- Comprobar la longitud del vector: `length()`
- Si los vectores son n√∫mericos, se les pueden aplicar las mismas operaciones que a los n√∫meros (suma, multuplicaic√≥n...), ya sea a un √∫nico vector o entre vectores (sumar un vector a otro). Ej.:
```{r}
vector1 <- c(1, 6, 4)
vector2 <- c(1, 2, 3)

vector1 + 10
vector1 + vector2
```
- Comparar dos vectores:
```{r}
vector1 == vector2
```
- Concatenar vectores: mismos comandos que para unir dos caracteres de texto. Ej.:
```{r}
paste(vector1, ":00", sep="")
paste(vector1, vector2, sep = " & ")
```
- Buscar si existe un valor concreto dentro de un vector. Ej.: 
```{r}
partidos1 <- c("PP", "PSOE", "SUMAR", "VOX")
partidos2 <- c("PP", "PSOE", "OTROS")
"VOX" %in% partidos1
"VOX" %in% partidos2
```
- Combinar vectores:
```{r}
long_vector <- c(partidos1, partidos2)
long_vector
```
- Conocer un elemento dentro de una posici√≥n concreta de un vector:
```{r}
num_vector <- 5:10
num_vector[3] # Elemento en la posici√≥n 3
num_vector[c(2, 4)] # Elementos en las posiciones 2 y 4
```
- Cambiar elementos espec√≠ficos de un vector: 
```{r}
num_vector[c(2, 4)] <- c(13, 50)
num_vector
```
- Explorar los primeros y √∫ltimos valores de un vector:
```{r}
head(long_vector, 2) # devuelve los dos primeros
tail(long_vector, 3) # devuelve los tres primeros
```

***
## Ficheros de datos (dataframes) {.tabset .tabset-fade .tabset-pills}
### 1. Apertura de ficheros
Para poder abrir un fichero no basta con el comando, sino que estos se deben guardar dentro de un nuevo objeto:
```r
datos<- read_csv("filename")
```
<br>

**Ficheros de texto plano (.csv, .txt, tsv, etc)**
Se necisita abrir la librer√≠a readr: `library(readr)`. El comando a utilizar var√≠a en funci√≥n del separador del archivo:

- `read_csv()` para ficheros csv delimitados por coma (,).
- `read_csv2()` para ficheros csv delimitados por punto y coma (;).
- `read_tsv()` lee ficheros separados por tabulador
- `read_delim()` lee ficheros sin delimitador
- `read_fwf()` lee ficheros de ancho fijo
- `read_table()` lee ficheros separados por espacio

Si las columnas tienen nombre, se debe especificar dentro de la funci√≥n:
```r
data<-read_csv("filename", col_names=FALSE)
```
<br>

**Ficheros de excel**
Cuando los datos est√°n un fichero **.xlsx**, utilizamos funci√≥n `read_excel()` del paquete **readxl**

Si los datos est√°n la primera hoja del fichero *mi_excel.xlsx*

```r
library(readxl)
datos <- read_excel("mi_excel.xlsx", 1)
```

Si los datos est√°n en una hoja llamada "mi_hoja"

```r
datos <- read.excel("mi_excel.xlsx", sheetName = "mi_hoja") 
```
<br>

**Lectura de datos desde ficheros SPSS, Stata y SAS **
Una de las opciones existentes es la funci√≥n `haven()` del paquete **haven** nos permite abrir ficheros en formatoStata/SPSS/SAS. Por ejemplo:

```r
library(haven)
datos <- read_dta("filename.dta")
```
Las funciones `read_spss()` y `read_sas()` tienen la misma sintaxis.

<br>

**Apertura manual de los ficheros**

Cuando los ficheros se abren as√≠, lo mejor es copiar el comando que se ha empleado y copiarlo en un chunk del rmd o el script en el que se est√© trabajadno, para que cuando se quiera volver a abrir el archivo sea m√°s rapido hacerlo.

***
### 2. Visualizar el contenido de un dataframe
- `View(datos)` ‚Üí abre una nueva pesta√±a con la base de datos.
- `glimpse(datos)` (del paquete tydiverse) ‚Üí muestra el n√∫mero de filas y de columnas, el nombre de las variables, su clase y los primeros valores de cada una de ellas.
```{r echo=FALSE, warning=FALSE}
glimpse(select(datos, 1:10))
```
- `dim(datos)` ‚Üí permite conocer el n√∫mero de filas y de columnas.
```{r echo=FALSE}
dim(datos)
```
- `summary(datos)` ‚Üí muestra los descriptivos principales de cada una de las variables del dataframe (media y cuartiles).
```{r echo=FALSE}
summary(select(datos, 1:5))
```
- `colnames(datos)` ‚Üí lista con el nombre de todas las variables.
```{r echo=FALSE}
colnames(select(datos, 1:15))
```
- `describe(datos)` (del paquete psych).
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(psych)
describe(select(datos, 1:10))
```
- `str(datos)` ‚Üí metadatos de cada una de las variables (lo que sale si le das al tri√°ngulo verde que aparece junto al nombre de la base de datos del environment).
```{r echo=FALSE}
str(select(datos, 1:5))
```
- `head(datos, 10)` ‚Üí muestra las variables, su clase, los 10 primeros valores de cada uno de ellos.
```{r echo=FALSE}
head(datos,10)
```
***
### 3. Modificar el fichero
#### Ordenar las variables

**Variable num√©rica:**

- Orden ascendente:
    + Opci√≥n 1: `datos %>% arrange(variable)`
    + Opci√≥n 2: `datos <- datos[order(datos$variable), ]`
- Orden descendente:
    + Opci√≥n 1: `datos %>% arrange(desc(variable))`
    + Opci√≥n 2: `datos <- datos[order(-datos$variable), ]`
- Se pueden ordenar los datos por dos variables simult√°neamente: 
    + Opci√≥n 1: `datos <- datos %>% arrange(var1, var1)`
    + Opci√≥n 2: `datos <- datos[order(datos$var1, datos$var2), ]`

**Variable categ√≥rica:**

- Se usan los mismos comandos anteriores para ordenar por orden alfab√©tico ascendente o descendente
- Orden personalizado: `mutate(variable = fct_relevel(variable, c("categor√≠a1", "cat2", "catn")))` Ej.:
  ```r
  mutate(partido = fct_relevel(party, c("PP", "PSOE", "VOX", "SUMAR", "Otros")))
  ```
<br>

#### Seleccionar (y eliminar) variables
Seleccionar una columna:
```{r}
select(Datos, age)
```

Seleccionar varias columnas: 
```{r}
select(Datos, name, sex, age)
```


Crear un nuevo data.frame con una selecci√≥n de columnas. Esto es muy √∫til cuando tenemos datasets con muchas variables y queremos trabajar con algo m√°s manejable:
```{r}
Nuevos_Datos <- select(Datos, name, sex, age) 
head(Nuevos_Datos, 10)  # visualizamos el nuevo dataset
```

Tambi√©ns se pueden eliminar una o varias variables que no se quieran en el dataset:
```{r}
Nuevos_Datos2 <- select(Datos, -name) 
head(Nuevos_Datos2, 10)
```


*Dataframe original, para comparar las diferencias:*
```{r echo=FALSE}
head(Datos, 10)
```


***
## Edici√≥n de variables  {.tabset .tabset-fade .tabset-pills}
### 1. Renombrar una variable
**Opci√≥n 1**:
```r
Datos <- rename(Datos, nombre_nuevo = nombre_viejo)
```
**Opci√≥n 2**:
```r
datos <- datos %>% rename(nombre_nuevo = nombre_viejo)
```
Se puede cambiar el nombre de varias variables a la vez:
```{r}
colnames(Datos)

Datos<-Datos %>% rename(
  clase=pclass,
  nombre=name,
  sexo=sex,
  edad=age)
```

```{r}
colnames(Datos)
```


***
### 2. Recodificar una variable (o crear una nueva)
*(Tanto `mutate` como `case_when` son comandos de la librer√≠a dplyr, que se incluye dentro del tidyverse)*

Antes de recodificar una variable es necesario conocer c√≥mo es la variable. Para ello:

1. Se mira de qu√© tipo es la varible (num√©rica -numeric/dbl- o factor) gracias al comando `class`:
```{r}
class(Datos$edad)
```
2. Tambien conviene realizar una tabla para conocer el contenido de la variable, as√≠ como su distribuci√≥n: 
```{r}
table(Datos$clase, useNA="ifany") #La opci√≥n useNA="ifany" es opcional, y se a√±ade para que en la tabla se muestren tambi√©n los valores perdidos.
```
<br>

**Recodificar con el comando case_when**

```r
Datos <- Datos %>%
  mutate(edad = case_when(
    edad == 29 ~ 30, # reemplaza 29 por 30
    edad == 2 ~ 3, # reemplaza 2 por 3
    TRUE ~ edad)) # Mantiene iguales los valores que no cambian.
```

```{r}
Datos <- Datos %>%
  mutate(clase_rec = case_when(
    clase %in% c(2, 3) ~ 0, # Si 'clase' es 2 o 3, asigna "0"
    TRUE ~ clase)) 

table(Datos$clase_rec)
```
La opci√≥n TRUE en este comando significa "todos los dem√°s valores". Si no se a√±adiera, todos los valores que no coinciden con las condiciones se enviar√≠an a perdidos (NA).

<br>

**Recodificar con el comando ifelse**

El comando ifelse es una secuancia l√≥gica con tres elementos. Un primer n√∫mero, que es la categor√≠a que se quiere transformar, un segundo n√∫mero, que es en el que se transforma, y una tercera condici√≥n para el resto de valores. Esta puede ser otro n√∫mero, NA o otra secuencia de ifelse.
```r
Datos <- Datos %>%
  mutate(edad = ifelse(edad == 29, 30, ifelse(edad == 2, 3, edad)))

Datos <- Datos %>%
  mutate(clase_rec2 = ifelse(clase == 1, 1,
                             ifelse(clase %in% c(2, 3), 0, NA)))
```
<br>

Las **variables categ√≥ricas** se recodifidan del siguente modo:

1. Transform√°ndolas en una variable num√©rica:
```r
#Por separado:
Datos <- Datos %>% 
  mutate(sexo = as.numeric(sexo)) %>% 
  mutate(sexo = case_when(
    sexo == 1 ~ 0,
    sexo == 2 ~ 1,
    TRUE ~ sexo
  ))
  
#A la vez:
Datos <- Datos %>% 
  mutate(as.numeric(sexo) = case_when(
    sexo == 1 ~ 0,
    sexo == 2 ~ 1,
    TRUE ~ sexo
  ))
```
*Es la opcion m√°s √∫til si se quiere modificar una variable con muchas categor√≠as*

2. Escribiendo las etiquetas entre "":
```r
Datos <- Datos %>%
  mutate(sexo = case_when(
    sexo == "female" ~ "mujer",  
    sexo == "male" ~ "hombre",   
    TRUE ~ sexo                  
  ))
```
*Esta opci√≥n es la m√°s c√≥moda si la variable tiene pocas categor√≠as.*

3. Especificando los niveles que se quieren modificar:
```r
datos <- datos %>%
  mutate(estudios_universitarios = case_when(
    estudios %in% levels(estudios)[1:5] ~ 0,  # Agrupar niveles 1 a 5 en 0
    estudios %in% levels(estudios)[6] ~ 1,    # Agrupar nivel 6 en 1 
    TRUE ~ NA_real_                           
  ))
```
*Esta opci√≥n es util si se quiere convertir en dicot√≥mica una variable categ√≥rica con muchas categor√≠as, aunque la primera opci√≥n es igual de buena en estos casos*

<br>

Otros **ejemplos** de recodificar variables:

- Se pueden utilizar s√≠mbolos l√≥gicos como el >,<,|,& etc a la hora de recodificar variables
```r
datos<-datos %>%
  mutate(recuerdo19 = ifelse(recuerdo19 >= 9977, NA, recuerdo19))
```



***
### 3. A√±adir etiquetas a la variable
Ver las etiquetas de una variable: `attr(datos$var, "labels")`:

**Para cambiar las etiquetas se usa el comando factor** *(de dyplr)*
```r
datos <- datos %>% 
  mutate(variable = factor(variable, 
                    levels = c(1,2,3),
                    labels = c("Etiqueta1","Etiqueta2","Eriqueta3")))
```
- `levels` = c(1,2,3) indica el conjunto de n√∫meros correspondientes con los valores de cada categor√≠a de la variable.
- `labels` =c("Etiqueta1"...) indica las etiquetas correspondientes con cada valor especificado anteriormente. Por ejemplo, en este caso a la categor√≠a de la variable que se identifica con un 1 se le asignar√≠a la etiqueta "Etiqueta1".
- Ej. de c√≥mo a√±adir etiquetas:

```{r}
table(datos$mujer)

datos <- datos %>%
  mutate(mujer = factor(mujer, levels = c(0, 1), labels = c("Hombre","Mujer"))) 

table(datos$mujer)
```



Si se quiere etiquetar alg√∫n car√°cter de una variable num√©rica sin transformarla en factor, se puede usar el siguiente comando:

```r
library(labelled)
val_labels(datos$variable) <- c(Etiqueta1 = 0, Etiqueta2 = 1)
```

Este comando tambi√©n es √∫til en el caso de escalas: por ejemplo, en la escala de ideolog√≠a del 1 al 10 para poner que el 1 es extrema izquierda y el 10 extrema derecha, pero dejarlo como num√©rico y sin necesidad de etiquetar todas las categor√≠as.
```{r include=FALSE}
library(labelled)
```

```{r}
class(datos$ideol)

val_labels(datos$ideol) <- c(Extrema_izq = 1, Extrema_dcha = 10)

class(datos$ideol)
val_labels(datos$ideol)
```

***
## An√°lisis descriptivo  {.tabset .tabset-fade .tabset-pills}
### 1. Estad√≠sticos b√°sicos

Lista con los estad√≠sticos descriptivos b√°sicos: `summary()`
```{r}
summary(datos$edad)
```

Tambi√©n se puede obtener un √∫nico estad√≠stico de inter√©s: `min()`, `max()`, `median()`, `mean()`, `sd()`

***
### 2. Tablas de frecuencias

Con el comando `table`:
```r
table(datos$variable)
```

* Ej.:

```{r}
table(datos$estudios)
```

Si queremos ver tambi√©n los valores perdidos de la variable, se a√±ade al comando original la opci√≥n `useNA = "ifany"`: 

```{r}
table(datos$estudios, useNA = "ifany")
```
<br>

Con el comando `count`:
```r
datos %>% count(variable)
```

* Ej.:
    
```{r}
datos %>% count(estudios)
```


*La explicaci√≥n de c√≥mo hacer tablas de frecuencias bivariadas, as√≠ como su interpretaci√≥n, est√° en el apartado de an√°lisis bivariado*

***
## An√°lisis bivariado  {.tabset .tabset-fade .tabset-pills}

### 1. Prueba estad√≠stica para la diferencia de medias (T-test) {.tabset .tabset-fade .tabset-pills}

#### 1.1. En R

**Test de una media**: 

El objetivo de este tipo de test es comprobar si la media poblacional de una variable se corresponde con una determinada cifra.
```r
t.test(datos$variable, mu = 5, conf.level = 0.99)
```

- `mu = n√∫mero` es donde se indica el valor de la media para el cual se quiere comprobar si la media poblacional es significativamente distinta. Es decir, si se quiere comprobar si la media es igual a 5, se escribir√° `mu = 5`.
- `conf.level` sirve para establecer un intervalo de confianza espec√≠fico. Si no se a√±ade esta opci√≥n, el intervalo ser√° al 95%.

```{r}
t.test(datos$ideol, mu=5.5)
```
En este caso, se puede decir que al 95% de confianza la media ideol√≥gica de la poblaci√≥n es distinta de 5.5 (en una escala del 1 al 10). Se sabe por tres motivos:

- El p-value es < de 0,05
- El valor de t < -1,96
- En el intervalo de confianza no se incluye el 5.5

*La explicaci√≥n del por qu√© est√° en el apartado de la teor√≠a*

<br>

**Test de proporciones**: para variables dicot√≥micas. 

Lo que se intenta con este tipo de test no es comprobar si una determinada cifra se incluye dentro de la media poblacional, sino si una variable alcanza un determinado porcentaje. 

P.ej., para saber si el PP puede alcanzar un 35% de los votos, se crea una variable dicot√≥mica donde 0 es no votarlo y 1 s√≠. Despu√©s, se hace un ttest como el anterior, pero en el mu se especifica el porcentaje que se quiere comprobar si se alcanza (0.35 en este caso).
```{r}
t.test(datos$intvoto_pp, mu=0.35)
```
Los resultados se interpretan igual que en el test de una media.

<br>

**Test de dos medias** 

La hip√≥tesis nula en este tipo de prueba es que las dos medias son iguales y la hip√≥tesis alternativa es que no lo son.
```r
t.test(datos$var1 ~ datos$var2)
```
- `var2` es la variable dicot√≥mica que divide a la muestra en los dos grupos de inter√©s, para los cuales se tratar√° de averiguar si la media de la
- `var1` (variable num√©rica) es igual en ambos o no.

```{r eval=TRUE}
t.test(datos$ideol ~ datos$hombre)
```
Los resultados indican que la media de ideolog√≠a de las mujeres en la muestra es 4.75 y la de los hombres 4.87. Esta diferencia es suficiente para rechazar la Ho, es decir, no existen diferencias significativas en la ideolog√≠a en funci√≥n del g√©nero.

<br>

**Comparaci√≥n de medias para dos variables num√©ricas**

Si son **muestras independientes**:

```r
t.test(datos$variable1, datos$variable2)
```


En el caso de **muestras dependientes**, el comando es el siguiente: 
```r
t.test(datos$variable1, datos$variable2, paired = TRUE)
```
La prueba t pareada se utiliza cuando las medias que estamos comparando no son independientes. En otras palabras:

- Correnponden al mismo conjunto de sujetos en dos momentos diferentes (por ejemplo, antes y despu√©s de un tratamiento).
- Se comparan dos variables medidas en las mismas personas o unidades (las mismas personas opinan o responden sobre dos cosas diferentes).

Ej.: comprobar si las personas tienen la misma probabilidad de votar al PP y VOX:
```{r}
t.test(datos$prop_vox, datos$prop_pp, paired=TRUE) 
```

<br>

*C√°lculo manual de los intervalos de confianza:*

La f√≥rmula de los intervalos es: media muestral ¬± valor cr√≠rico (œÉ)*error estandar

Para calcular el error, se utiliza el comando `std.error`de la librer√≠a `plotrix`:
```r
std.error(datos$variable)
```
```{r include=FALSE}
library(plotrix)
```
En el ejemplo usado en el test de una media, el error se calcular√≠a del siguiete modo:
```{r}
std.error(datos$ideol)
```
El error est√°ndar es 0.016. De acuerdo con esto, al 95% los intervalos ser√≠an:

- Intervalo superior: 4.815857 + 1.96*0.01568334 = 4.775456
- Intervalo inferior: 4.815857 - 1.96*0.01568334 = 4.856257


***
#### 1.2. Teor√≠a
A la hora de iterpretar los resultados de una prueba estad√≠stica, podemos fijarnos en tres cuestiones (relacionadas entre s√≠): el valor cr√≠tico, el nivel de significatividad o alpha y el intervalo de confianza.

- *Nivel de confianza*: es la probabilidad de que el par√°metro a estimar se encuentre en el intervalo de confianza.
- *Alpha*: es la probabilidad de quedarse fuera de ese intervalo (en t√©rminos sustantivos, la probabilidad de rechazar la hip√≥tesis nula cuando es cierta.
- *Valor cr√≠tico*: indica el n√∫mero de desviaciones est√°ndar que cubren el √°rea bajo la curva para un determinado nivel de confianza. Por ejemplo, para un IC del 95%, este valor cr√≠tico indica los l√≠mites dentro de los cuales se encuentra el 95% de las observaciones en una distribuci√≥n normal. Establece donde empieza y d√≥nde termina la zona de rechazo de la hip√≥tesis.


|Nivel de confianza|Alpha|Valor cr√≠tico|
| :---: | :----: | :----: |
|95%|5 - 2,5%|1,96|
|99%|1 - 0,5%|2,57|
|99,9%|0,1 - 0,05%|3,27|


<center>
![Intervalos de confianza](01_img/intervalo_confianza.png){width=320px}
</center>

El *intervalo de confianza* indica, para un determiando nivel de confianza, el rango en el que se mover√° la media real de un determinado rasgo para el universo estudiado, mientras que la media que se puede calcular a partir de una muestra indica √∫nicamente el valor medio del rasgo de esa muestra. Es decir, si tomamos un intervalo de confianza del 95%, en el 95% de ocasiones la media real del universo de estudio se mover√° entre los l√≠mites establecidos por el intervalo de confianza. Se emplean estos intervalos ya que la √∫nica forma de conocer el valor medio real de un determinado rasgo de una poblaci√≥n completa es mediante un censo en el que se incluya a toda esa poblaci√≥n, pero es imposible de conocer de forma exacta tomando solo una muestra poblacional.

Por ejemplo, si para la media idol√≥gica tenemos un intervalo que va del 4,5 al 5 para un nivel de confianza del 95%, lo que quiere decir es que, en el caso de realizar 100 encuestas independientes a una poblaci√≥n, en 95 de estas encuestas la media muestral tendr√° un valor situado entre el 4,5 y el 5, y en otros 5 caso ser√° superior o inferior a estas cifras. 


***
### 2. An√°lisis de correlaci√≥n  {.tabset .tabset-fade .tabset-pills}

#### 2.1. En R
Los an√°lisis de correlaci√≥n buscan averiguar si existe relacion entre dos variables continuas.

<br>

**Covarianza:** 
```r
cov(datos$var1, datos$var2)
```
Ej. Se quiere comprobar la relaci√≥n entre en √≠ndice de corrupcion de un p√°is (*cpi*, donde 0=m√°s corrupto; 10=menos corrupto) y el √≠ndice de desarrollo humano (*hdi*, donde 0=m√°s bajo; 1=m√°s alto).
```{r message=FALSE, warning=FALSE}
cov(data$cpi, data$hdi)
```
<br>

**Correlaci√≥n de Pearson:** 

La funi√≥n para calcular la correlaci√≥n es `cor()` *(funciona igual que el comando cov)*. Sin embargo, para poder interpretar m√°s adecuadamente los resultados de la correlacion conviene realizar un test para comprobar si dicha correlaci√≥n es estad√≠sticamente significativa. Las hip√≥tesis de este test son:

* H~0~= la correlaci√≥n es igual a 0, as√≠ que no hay relaci√≥n
* H~1~= la correlaci√≥n es significativamente distinta de 0

```r
cor.test(datos$var1, datos$var2)
```
Ej.:

```{r}
cor(data$cpi, data$hdi) # devuelve el valor de la correlaci√≥n
cor.test(data$cpi, data$hdi) # hace un test
```
Los resultados muestran que la correlaci√≥n entre ambas variables tiene un valor de 0,72. El test arroja tres resultados:

* t=13,186 --> t>3,26
* p<2.2e-16 --> p<0,001
* IC= [0.6406049, 0.7902298]

Bas√°ndonos en estos resultados, podemos rechazar la hip√≥tesis nula y afirmar que la correlaci√≥n es significativamente distinta de cero para un nivel de confianza del 99,9%

<br>

**Correlaci√≥n de m√°s de dos variables a la vez:**
```{r include=FALSE}
#Para estos ejemplos se usa la base de datos mtcars, que viene inclu√≠da con R.
attach(mtcars)
Data <- mtcars
```

1. Correlaci√≥n entre todas las variables del dataset. Es fundamental que sean TODAS num√©ricas.

```{r}
cor(Data)
```

2. Si solo se quiere la relaci√≥n entre varias variables concretas, se puede hacer de forma manual del siguiente modo:

```{r}
x <- Data[c(1:3, 5)]
y <- Data[6:8]
cor(x, y)
```
<br>

**Visualizaci√≥n de correlaciones:**

Adem√°s de usar funciones de c√°lculo, suele ser de gran ayuda visualizar las correlaciones entre variables gr√°ficamente.

- Nube de puntos (dos variables): 
```{r}
plot(data$cpi, data$hdi, #Los datos que se van a usar para hacer el gr√°fico
     main = "CPI/HDI", #El t√≠tulo del gr√°fico
     xlab = "Corruption perception index", #El texto del eje X
     ylab = "Human development index", #El texto del eje Y
     pch = 18) #Establece la forma de los puntos (tri√°ngulos, c√≠rculos, x...)
```
  
- Correlaciones para m√°s de dos variables a la vez: 

```r
library(corrgram)
corrgram(datos)
```
Ej.:
```{r include=FALSE}
library(corrgram)
```
```{r}
corrgram(Data)
```

*El comando cuenta con numerosas argumentos extra para modificar y mejorar la visualizaci√≥n del gr√°fico final (ver ?corrgram). P. ej.:*
```{r}
corrgram(Data, order=TRUE, lower.panel=NULL,
         upper.panel=panel.pie, text.panel=panel.txt,
         main="Car Milage Data in PC2/PC1 Order")
```

***
#### 2.2. Teor√≠a
Si queremos analizar la dependencia entre dos **variables continuas** XX e YY, no podemos estudiar sus distribuciones por separado, sino que debemos hacerlo de manera conjunta. Para ello, definimos una variable estad√≠stica bidimensional (X,Y)(X,Y), cuyos valores ser√°n todos los pares formados por los valores de las variables XX e YY.

La representaci√≥n gr√°fica m√°s utilizada para examinar la relaci√≥n entre dos variables num√©ricas es el diagrama de dispersi√≥n. Este consiste en representar, sobre un plano cartesiano, los puntos correspondientes a los pares de valores ($x_{i}$, $y_{i}$) de la variable bidimensional. Estas nubes de puntos nos permiten visualizar el tipo de relaci√≥n existente entre las variables (lineal, exponencial, positiva, negativa, etc.). Si adem√°s queremos cuantificar la intensidad de dicha relaci√≥n, es necesario recurrir a medidas estad√≠sticas, como la covarianza muestral o el coeficiente de correlaci√≥n.

La **covarianza** de una variable bidimensional se obtiene promediando los productos de las desviaciones de cada valor con respecto a las medias de XX e YY. Una vez calculadas las medias, podemos calcular la covarianza siguiendo la siguiente f√≥rmula:

$$cov_{x,y} = \frac{\sum\limits_{i=1}^{n}{(x_i-\overline{x}) \cdot (y_i-\overline{y})} }{n-1}$$

El valor de la covarianza nos indica lo siguiente:

* Si cov>0, relaci√≥n lineal creciente entre las variables
* Si cov<0, relaci√≥n lineal decreciente entre las variables
* Si cov=0, no existe relaci√≥n lineal entre las variables

El problema de esta medida es que depende de las unidades. Imaginemos que las unidades de la variable x son _cm_ y las de la variable y son _gr_. En este caso, las unidades de la covarianza ser√°n _cm √ó gr_, y si cambiamos la escala de las variables, la covarianza tambi√©n cambiar√°. Esto hace que el valor de la covarianza sea dif√≠cil de interpretar. (la variazna es la distancia de los puntos hacia los ejes. La covarianza es la distancia de los puntos entre s√≠)

Para evitar este problema, es recomendable utilizar una medida normalizada, como el coeficiente de **correlaci√≥n de Pearson**, que toma valores entre -1 y 1, donde:

* œÅ =  1 indica una relaci√≥n lineal perfecta y positiva
* œÅ = -1 indica una relaci√≥n lineal perfecta y negativa
* œÅ =  0 indica ausencia de relaci√≥n entre las variables

$$\rho = \frac{\text{cov}(X,Y)}{\sigma_x \sigma_y}$$

**Correlaci√≥n no implica causalidad**

La correlaci√≥n entre dos variables v1 y v2 puede deberse a:

* Relaci√≥n causal: V1 es la causa, V2 el efecto (o viceversa)
* Azar
* Variable interviniente (confounding factor):
    + [Relaciones esp√∫reas](http://www.tylervigen.com/spurious-correlations): es una correlaci√≥n aparente entre dos variables que en realidad es causada por la influencia de una tercera variable, conocida como variable de confusi√≥n. Aunque las dos variables parecen estar relacionadas, su relaci√≥n no es causal.
    + [Paradoja de Simpson](https://upload.wikimedia.org/wikipedia/commons/f/fb/Simpsons_paradox_-_animation.gif): ocurre cuando una tendencia observada en varios grupos desaparece o se invierte al combinar los datos de esos grupos. Esto sucede debido a la influencia de una variable oculta o de confusi√≥n que afecta la interpretaci√≥n de la relaci√≥n entre las variables. Aqu√≠ ten√©is un [ejemplo muy conocido](https://rpubs.com/dawnwp/1081716).

***
### 3. Tablas de contingencia {.tabset .tabset-fade .tabset-pills}

#### 3.1. En R
Permite conocer la relaci√≥n existente entre variables categ√≥ricas. Para ello nos valemos de las tablas de contingencia, donde se muestran las frecuencias de dos variables.

**La funci√≥n table()**

1. Crear la tabla con las dos variables y guardarla: 
```r
tabla <- table(datos$var1, datos$var2)
```
Ej.: 
```{r}
tabla <- table(datos$situ_lab, datos$hombre)  # (filas, columnas)
tabla
```

*La primera var son las filas de la tabla y la segunda las columnas. La variable con menos categor√≠as se pone en las columnas porque as√≠ es m√°s sencillo de visualizar e interpretar, creando una tabla que se extiende de forma vertical en lugar de horizontal (mejor la primera tabla que la segunda).*

2. Crear la tabla de frecuencias:

- `prop.table(tabla)` #porcentaje de tabla (el % sobre el total)
- `prop.table(tabla, 1)` # porcentajes de fila (el 100% lo suman las filas)
- `prop.table(tabla, 2)` # porcentajes de columna (el 100% lo suman las columnas)
Para leer estas tablas adecuadamente, hay que fijarse si el 100% lo suman las filas, las columnas o toda la tabla.

Ej.:
```{r}
prop.table(tabla)   
```
Indica el porcentaje de cada subgrupo sobre el total de la muestra. Por ejemplo, de esta tabla se puede deducir que del total de la poblaci√≥n un 25% son mujeres trabajadoras.
```{r}
prop.table(tabla, 1)
```
Indica la composici√≥n de g√©nero de cada una de las situaciones laborales. Por ejemplo, de los trabajadores un 44% son mujeres y un 56% hombres.
```{r}
prop.table(tabla, 2)
```
Inidca el perfil laboral dentro de cada g√©nero. Por ejemplo, un 54% de las mujeres son trabajadoras, mientras que un 63% de los hombres son trabajadores.

<br>

**Otras tablas: xtabs vs CrossTable** (mejor usar esta)

* `xtabs()`:

```r
tabla2 <- xtabs(~var1+var2, data = datos) #Crear y guardar la tabla
ftable(tabla2) #Visualizar la tabla
summary(tabla2) #Para ver los estad√≠sticos de la tabla (como el chi2 y el p-valor)
```
Ej.:
```{r}
tabla2 <- xtabs(~situ_lab+hombre, data=datos)
ftable(tabla2) 
summary(tabla2) 
```

* `CrossTable()`:

```r
library(gmodels)
tabla3 <- CrossTable(datos$var1, datos$var2, #Las variables
                     digits = 1, #El n√∫mero de decimales de la tabla
                     #Otras opciones de la tabla,
                     format = "SPSS") #El formato de salida de la tabla
```
```{r include=FALSE}
library(gmodels)
```
Ej.:
```{r}
CrossTable(datos$situ_lab, datos$hombre, digits=1, expected=T, asresid=TRUE, chisq=TRUE, prop.chisq=F, format="SPSS")
```
*Para comprobar qu√© opciones se pueden aplicar a la tabla, conviene mirar `?(CrossTable)`*

Ej. de interpretaci√≥n de los residuos ajustados: en la celda de mujer y trabajadoras, los residuos ajustados son de -17,9. Esta cifra es inferior a -3,27, por lo que podemos decir que con un nivel de confianza del 99,9% las mujeres se encuentran infrarepresentadas (el s√≠mbolo es negativo) dentro del grupo de los trabajadores.

***
#### 3.2. Teor√≠a
Las hip√≥tesis a comprobar en una tabla de contingencia son: 

* H~0~= no existe asociaci√≥n entre las variables (son independientes)
* H~1~= s√≠ existe asociaci√≥n entre las variables

Para saber si existe relaci√≥n entre las bariables debemos fijarnos en:

<br>

**El an√°lisis de los residuos**

A la hora de examinar la asociaci√≥n entre variable categ√≥ricas es importante diferenciar entre:

* Frecuencia observada: la frecuencia en la muestra
* Frecuencia esperada: la frecuencia que observar√≠amos en el caso de que __no hubiera relaci√≥n entre las 2 variables__
* Residuo: diferencia entre el valor observado y el esperado, que manifiesta dependencia entre pares de valores cuando es distinto de cero. Cuanto mayor sea el residuo, mayor ser√° la probabilidad de que la muestra provenga de una poblaci√≥n en la que las variables est√©n relacionadas. Para determinar si el valor de los residuos es significativo, es necesario estandarizarlos.

Si el residuo ajustado es mayor (en t√©rminos absolutos) que el valor cr√≠tico para un determinado nivel de confianza (1,96 para el 95%), se puede decir que la diferencia entre los valores esperados y los ajustados para una celda concreta de la tabla es significativa. En funci√≥n de si el signo de estos residuos es positivo o negativo, sabremos si la relaci√≥n establecida en la celda es de sobrerrepresentaci√≥n dentro de la muestra (signo +) o de infrarrepresentaci√≥n (signo -). *(Hay un ejemplo de esto al final de la explicaic√≥n de CrossTables en R)*

<br>

**Chi2**

El chi-cuadrado (œá¬≤) es una prueba estad√≠stica que se utiliza para comparar frecuencias observadas con frecuencias esperadas, a fin de determinar si hay una diferencia significativa entre ellas. Se emplea com√∫nmente para analizar tablas de contingencia y evaluar si dos variables categ√≥ricas est√°n relacionadas. Elùúí2 se define como: 

$$\chi^2 = \sum \frac {(O - E)^2}{E}$$
Donde:

* O = Frecuencias observadas
* E = Frecuencias esperadas 

Por ser suma de cuadrados, se cumple que ùúí2‚â•0:

* ùúí2=0 cuando las variables son independientes
* ùúí2 crece a medida que aumenta la dependencia entre las variables

Sabemos que el valor de chi-cuadrado (œá¬≤) es lo suficientemente alto para ser significativo compar√°ndolo con un valor cr√≠tico de una tabla de chi-cuadrado, o mediante su p-valor.


***

## Regresiones {.tabset .tabset-fade .tabset-pills}
### Lineal {.tabset .tabset-fade .tabset-pills}
#### En R
La regresi√≥n lineal se usa para predecir el valor de una variable **y** en funci√≥n de una o m√°s variables **x**. La variable dependiente debe ser num√©rica, y las independientes pueden ser tanto num√©ricas como categ√≥ricas. *En el ejemplo usado, se tratar√° de comprobar si el √çndice de Corrupci√≥n de un pa√≠s (y) depende del nivel de PIB de este (x).*

A la hora de realizar un an√°lisis de regresi√≥n adecuado se deben seguir los siguientes pasos:

1. [An√°lisis preliminar](#preliminar)
2. [Realizar el modelo de regresi√≥n](#modelo)
3. [Interpretar los resultados](#resultados)
4. [Supuestos del modelo](#supuestos)
5. [Exportar los resultados](#exportar-resultados)

<br>

##### Resumen de las funciones principales
```r
# An√°lisis preliminar:
scatter.smooth(x=datos_reg$var1, y=datos_reg$var2) #Gr√°fico de dispersi√≥n
boxplot(datos_reg$var1, sub=paste("Outlier rows:  ", boxplot.stats(datos_reg$var1)$out)) #Boxplot para buscar datos at√≠picos
ggplot(datos_reg, aes(var1)) + geom_density(fill="red", alpha=0.8) #Diagrama de densidad (librer√≠a ggplot)

# Funci√≥n de la regresi√≥n
regresi√≥n <- lm(var1~var2, datos_reg) #Librer√≠a e1071
summary(regresi√≥n)

# Comprobaci√≥n de los supuestos principales
plot(regresi√≥n,2) #Normalidad de los residuos
bptest(regresi√≥n) #Homocedasticidad (librer√≠a lmtest)
vif(regresi√≥n) #Multicolinealidad (librer√≠a rms)

#Exportar los resultados
stargazer(regresi√≥n, type="text") #Librer√≠a stargazer
```

<br>

##### An√°lisis preliminar {#preliminar}

Antes de estimar la regresi√≥n, es importante explorar y entender la variable dependiente (fen√≥meno que queremos explicar). 

1. **Gr√°fico de dispersi√≥n**: permite visualizar la relaci√≥n lineal entre la variable independiente y la dependiente. (Es una l√≠nea de tendencia, no un gr√°fico de dispersi√≥n, por eso la l√≠nea no es recta)

```{r}
scatter.smooth(x=datos_reg$gdp, y=datos_reg$cpi, main="GDP ~ CPI", xlab="GDP", ylab="CPI")
```

2. **Boxplot**: permite detectar la presencia de observaciones at√≠picas (outliers). Los valores at√≠picos pueden afectar a la predicci√≥n, modificando la direcci√≥n/pendiente de la recta de regresi√≥n.

```{r}
boxplot(datos_reg$gdp, main="GDP", sub=paste("Outlier rows:  ", boxplot.stats(datos_reg$gdp)$out)) 
```
  
  + Si se quiere comprobar con qu√© caso se corresponden los valores at√≠picos detectados se puede usar el siguiente comando:
  
```{r}
# Seleccionamos el nombre del pa√≠s cuyo GDP es igual a 30491.34375
outlier_gdp <- datos_reg %>%
  filter(gdp == 30491.34375) %>% 
  pull(cname)
table(outlier_gdp)
```

3. **Diagrama de densidad**: para ver la distribuci√≥n de la variable. Idealmente, la distribuci√≥n ha de ser cercana a la normal. Si esto no ocurre, ser√° necesario realizar alguna transformaci√≥n en los datos empleados.
```{r warning=FALSE}
ggplot(datos_reg, aes(cpi)) + geom_density(fill="red", alpha=0.8)
```
<br>

##### El modelo de regresi√≥n {#modelo}

La funci√≥n utilizada para construir modelos lineales es `lm()` del paquete `e1071`, que toma dos argumentos principales: `lm(var_dependiente ~ var_independiente, datos)`

```{r}
library(e1071)
reg.lineal <- lm(cpi~gdp, data=datos_reg) #El argumento "data=" se puede omitir, basta con poner la base de datos. Es decir, se puede escribir directamente: lm(cpi~gdp, datos_reg)
reg.lineal #Conviene guardar las regresiones dentro de un objeto, ya que de otra forma no se podr√≠an realizar los pasos posteriores.
```
<br>

##### Los resultados de la regresi√≥n {#resultados}

Para evaluar los resultados, imprimimos las estad√≠sticas de resumen para el modelo:
```{r}
summary(reg.lineal)
```

* Los **coeficientes** indican la contribuci√≥n de cada variable independiente al modelo de regresi√≥n. 
  + **Intercept**(Œ≤~0~). Establece el valor de la variable y cuando la varible x es 0 (el punto donde la recta de regresi√≥n corta la ordenada en el or√≠gen). En el *ejemplo*, el intercepto (Œ≤0)= 24.237, lo que significa que, para un pa√≠s con GDP=0, el valor de su cpi ser√≠a 24.237.
  + El *coeficiente* de la variable independiente: establece el incremento promedio que experimentar√° la variable dependiente (y) por cada unidad que se incremetne la variable independiente (x). En el ejemplo, el coeficiente del gdp (Œ≤1)=0.002163, lo que significa que por cada incremento de un dolar en el gdp de un pa√≠s, el cpi aumenta en 0.002163 puntos.
* La evaluaci√≥n de la **significatividad** de los coeficientes (Œ≤i) comienza con la definici√≥n de hip√≥tesis sobre los valores de los par√°metros poblacionales:
  + Hip√≥tesis nula: H0: Œ≤i=0 (el valor del coeficiente en la poblaci√≥n es 0).
  + Hip√≥tesis alternativa: H1: Œ≤i‚â†0 (el valor del coeficiente en la poblaci√≥n es distinto de 0).
  + En el summario de la regresi√≥n, se puede comprobar observando el valor de la columna con *t value* (muestra la prueba t asociada a cada  Œ≤~i~) o el *p-valor* de la columna Pr (> | t |).
* La **bondad de ajuste** del modelo (R^2^) mide el porcentaje de varianza de la variable dependiente (Y) que queda explicado con nuestro modelo. Var√≠a entre 0 y 1, y puede interpretarse como un porcentaje. Sin embargo, a medida que agregamos nuevas variables al modelo, el valor R-Squared ser√° mayor. *Adj R-Squared* penaliza por el n√∫mero de par√°metros en el modelo. Por lo tanto, al comparar modelos anidados, es una buena pr√°ctica observar el valor de R^2^ ajustado sobre R^2^. *En el ejemplo, podemos decir que un 74,67% de la variaci√≥n en el √≠ndice de corrupci√≥n se puede explicar gracias a las diferencias en el PIB*.
* La **significatividad del modelo** (F de Snedecor). Un F estad√≠sticamente significativo significa que al menos uno de los coficientes es estad√≠sticamente significativo. Es decir, que nuestro modelo predice mejor que un modelo sin variables.

<br>

##### Diagn√≥stico de la regresi√≥n (comprobaic√≥n de los supuestos) {#supuestos}

1. **Linealidad**. El supuesto de linealidad puede ser comprobada con un gr√°fico de Residuos vs Valores Predichos.La l√≠nea horizontal, sin patrones distintivos en los puntos, indica una relaci√≥n lineal.
 
```{r}
plot(reg.lineal, 1)
```

2. **Normalidad de los residuos**.
  i. El gr√°fico QQ de residuos puede usarse para comprobar visualmente el supuesto de normalidad. En este gr√°fico, los residuos deber√≠a seguir aproximadamente una l√≠nea recta.

```{r}
plot(reg.lineal, 2)
```

  ii. Cuando la visualizaci√≥n no es clara y tenemos dudas, podemos hacer un test. Por ejemplo, el de Shapiro-Wilk. La Ho en este test es que los residuos est√°n normalmente distribuidos (lo que queremos). El problema de este test es que est√° limitado a bases de datos con n menor a 5000 casos. Los resultados confirman que no podemos rechazarla.

```{r}
norm=rstudent(reg.lineal)
shapiro.test(norm)
```

Usando estos mismos datos, tambi√©n se puede comprobar que la media de los residuos es igual a 0, lo que se calcula gracias a la media. Idealmente, debemos encontrar un valor muy pr√≥ximo a cero.

```{r}
mean(reg.lineal$residuals)
```

  iii. Histograma de los residuos.
```{r}
hist(reg.lineal$residuals, freq = F)
# Para superponer la curva normal
m<-mean(reg.lineal$residuals)
std<-sqrt(var(reg.lineal$residuals))
curve(dnorm(x, mean=m, sd=std), col="darkblue", lwd=2, add=T)
```
*No es necesario hacer las tres opciones, sino que con elegir una es suficiente.*

3. **Homocedasticidad**. 
  i. Este supuesto puede comprobarse examinando el diagrama de scale-location. El gr√°fico muestra si los residuos se distribuyen equitativamente a lo largo de los rangos de las variables independientes. Deber√≠amos de observar una l√≠nea horizonal, sin fuertes tendencias.
```{r}
plot(reg.lineal, 3)
```
  ii. Para tener un resultado m√°s concluyente, hacemos un test de heterocedasticidad. La Ho en este test es que la varianza de los residuos es constante (homoced√°stica, lo que queremos). La evidencia no permite rechazar la hip√≥tesis nula, por lo cual afirmamos que la distribuci√≥n es homoced√°stica.

```{r}
p_load(lmtest)
bptest(reg.lineal)
```

*Para este supuesto es mejor el test que la im√°gen (m√°s dificil de interpretar)*

4. **Independencia de los residuos** Durbin Watson permite examinar si los residuos se autocorrelacionan con ellos mismos. La Ho en este test es que no est√°n autocorrelacionados (lo que queremos). Esta prueba podr√≠a ser especialmente √∫til cuando tenemos series temporales (correlaci√≥n serial, encuestas tipo panel). Por ejemplo, esta prueba podr√≠a decirte si los residuos en el momento T1 est√°n correlacionados con los residuos en el momento T2 (no deber√≠an estarlo). En los datos de secci√≥n cruzada es menos com√∫n, aunque posible (correlaci√≥n espacial). 

```{r}
p_load(car)
durbinWatsonTest(reg.lineal)
```
p-value>0.5. No podemos rechazar la Ho, lo que indica que los errores no est√°n autocorrelacionados (lo que queremos).

5. **Multicolinealidad**. Hace referencia a la correlaci√≥n entre las VIs. Podemos medir la existencia de multicolinealidad usado el **VIF** (Variation Inflation Factor). Si el valor est√° por debajo de 5 est√° bien, no hay multicolinealidad. Por encima, si no sobrepasa demasiado esta cifra, y las variables que correlacionan son importantes para el an√°lisis que se quiere realizar, se puede aceptar este supuesto aunque la multicolinealidad sea superior a 5.
```{r}
p_load(rms)
vif(reg.lineal)
```

<br>

**Hacer los test a la vez**

1. Con la funci√≥n `plot()` de R base para obtener todos los gr√°ficos de manera conjunta.

```{r}
par(mfrow=c(2,2))
plot(reg.lineal, pch=23 ,bg='red', cex=2) 
```
Hemos visto arriba c√≥mo interpretar gr√°ficos 1-3. El gr√°fico inferior-derecha nos ayuda a detectar casos influyentes. **Leverage** es una medida de cu√°nta influencia ejerce cada punto la recta de regresi√≥n. No todos los valores at√≠picos son influyentes en el an√°lisis de regresi√≥n lineal. Al contrario, se puede dar el caso de que haya valores extremos que no son determinantes a la hora de estima la recta de gresi√≥n, por lo que los resultados no ser√≠an muy diferentes si los exclu√≠mos del an√°lisis. Sin embargo, si los casos est√°n fuera de la *distancia de Cook* (lo que significa que tienen puntuaciones de distancia de Cook altas), los resultados de la regresi√≥n se alterar√°n si excluimos esos casos. Para un buen modelo de regresi√≥n, la l√≠nea suavizada roja debe permanecer cerca de la l√≠nea media y ning√∫n punto debe tener una distancia de Cook grande. Si queremos identificar esos puntos en concreto (son los que se indican con un *):
```{r}
influence.measures(reg.lineal)
```

2. Gloval Validation of Linear Models Assumptions (paquete `gvlma`). 
```{r}
p_load(gvlma)
gvlma::gvlma(reg.lineal)
```
Concretamente:

* **Global Stat** mide si relaci√≥n entre las VIs y la VD es realmente lineal. El rechazo de la Ho indica que la relaci√≥n no es lineal.
* **Skewness** mide si la distribuci√≥n est√° sesgada y necesita una transformaci√≥n para cumplir con el supuesto de normalidad. El rechazo de la Ho indica que los datos deber√≠an ser transformados.
* **Kurtosis** mide si la distribuci√≥n es leptoc√∫rtica o platic√∫rtica. El rechazo de la Ho indica que los datos deber√≠an ser transformados.
* **Link Function** indica si la variable dependiente es realmente continua o es categ√≥rica. El rechazo de la Ho indica que ser√≠a conveniente usar un modelo alternativo de regresi√≥n, como el log√≠stico o la regresi√≥n binomial.
* **Heteroscedasticity** mide el supuesto de homocedasticidad. El rechazo de la Ho indica que los residuos son heteroced√°sticos, y que el modelo precide unos rangos de la variable dependiente mejor que otros.

*En la pr√°ctica, lo importante es mirar los siguientes supuetos: multicolinealidad (sobre todo esta, porque se puede ver a simple vista si sabes del tema) y homocedasticidad.*

<br>

##### Exportar los resultados {#exportar-resultados}
Esta librer√≠a cuenta con numerosas opciones para modificar la tabla con los resultados (`?stargazer`)
```{r}
p_load(stargazer)
stargazer(reg.lineal,
          type="text",
          dep.var.labels=c("Corruption Perception Index"),
          covariate.labels=c("GDP","cte"))
```

***
#### Teor√≠a
**Objetivos**:

* **Estimar/predecir** los valores que adoptar√° la variable dependiente (VD) a partir de valores conocidos del conjunto de variables independientes (VIs).
* **Cuantificar** la relaci√≥n de dependencia. Es decir, determinar qu√© proporci√≥n de varianza de la VD queda explicada por la suma de VIs.
* **Determinar el grado de confianza** con que se puede afirmar que la relaci√≥n observada en los datos muestras se da en la poblaci√≥n.

<br>

**Regresi√≥n lineal simple**

Cuando hacemos una regresi√≥n lineal modelamos una variable continua **y** como una funci√≥n matem√°tica de una o m√°s variables **xi**, de manera que podamos usar ese modelo de regresi√≥n para predecir **y** cuando solo conozcamos **xi**. Hablamos de regresi√≥n simple cuando s√≥lo est√°n involucradas dos variables. En este caso, la ecuaci√≥n de regresi√≥n se puede generalizar de la siguiente manera:

* F√≥rmula matem√°tica:

$$y = \beta_1 + \beta_2 x$$

* F√≥rmula regresiva:

$$\hat{y} = \hat{\beta}_1 + \hat{\beta}_2 + u$$
donde **Œ≤1** es la ordenada en el origen (o lo que es lo mismo, el valor de y cuando xi = 0) y **Œ≤2** es la pendiente de la recta. En conjunto, se denominan coeficientes de regresi√≥n. El t√©rmino u es el t√©rmino de error, es decir, la parte de variable dependiente que el modelo de regresi√≥n no puede explicar. Gr√°ficamente:

<center>

![Intervalos de confianza](01_img/explicacion_regresion.png){width=320px}
</center>

<br>

**M√≠nimos Cuadrados Ordinarios (MCO)**

Mediante la regresi√≥n lineal de una variable y sobre una variable x, buscamos una funci√≥n que sea una aproximaci√≥n de una nube de puntos (x~i~, y~i~). Por una nube de puntos, sin embargo, pasan infinitas rectas. Para conocer cu√°l es la m√°s adecuada, se emplea el m√©todo de MCO (OLS en ingl√©s) para estimar los par√°metros del modelo (*Œ≤~i~*).El m√©todo de los m√≠nimos cuadrados se utiliza para calcular la recta de regresi√≥n lineal que minimiza los residuos, esto es, las diferencias entre los valores reales observados (yi) y los valores estimados por la recta (\hat{y}~i~).

<br>

**Bondad de ajuste del modelo**

El m√©todo de m√≠nimos cuadrados selecciona la l√≠nea que m√°s se ajusta a nuestras observaciones. Sin embargo, que esa recta sea la mejor, no quiere decir que sea necesariamente buena. Para determinar la bondad de ajuste de nuestro modelo vamos a utilizar el Coeficiente de Determinaci√≥n R^2^.

El coeficiente de determinaci√≥n explica cu√°nta varianza de la variable dependiente podemos explicar con nuestro modelo. Su valor puede oscilar entre 0 y 1. Cuanto mayor sea su valor, m√°s preciso ser√° el modelo de regresi√≥n. A menudo se interpreta como un porcentaje.

<br>

**Supuestos de la regresi√≥n**

Para ver si un modelo de regresioÃÅn lineal ajustado es vaÃÅlido, debemos comprobar que se cumplen estas tres condiciones sobre los residuos:

1. Independencia: los residuos deben ser independientes entre s√≠
2. Homocedasticidad: para cada valor de la variable x, la varianza de los residuos ei debe ser la misma (es decir, que el ajuste es igual de preciso independientemente de los valores que tome x).
3. Normalidad: para cada valor de la variable independiente x, los residuos ei se distribuyen normalmente con media 0.

Adem√°s:

4. La relaci√≥n entre las variables x e y es lineal.
5. Ausencia de multicolinealidad (dos de las variables independientes est√°n muy correlacionadas, una explica la otra).

***


### Lineal m√∫ltiple

Llamamos regresi√≥n lineal m√∫ltiple al an√°lisis de regresi√≥n que incluye m√°s de una variable independiente. Se representa como:

$$E(y) = \beta_{0}  + \beta_{1}{x_{1}} + \ \beta_{12}{x_{2}} +  \beta_{3}{x_{3}} + u$$

donde __Œ≤~0~__ es el valor de _y_ cuando todas las _x~i~_ valen 0, __Œ≤~i~__ son los coeficientes de las variables independientes y el t√©rmino __u__ es el t√©rmino de error. 

Esta ecuaci√≥n definir√≠a un hiperplano, pues con una VI se define una recta, con dos VIs un plano, con tres VIs un espacio de tres dimensiones, y as√≠ sucesivamente.

**Apartados:**

1. [Preparar la base de datos (eliminar NA)](#eliminarNA)
2. [Modelo de regresi√≥n y resultados](#modeloreg)
3. [Visualizaci√≥n de los coeficientes](#coef)
4. [Supuestos del modelo](#supuestoS)
5. [Valores predichos e intervalos de confianza](#predichos)
6. [Exportar los resultados](#Exportar)
7. [Comparaci√≥n de modelos](#comparar_modelos)

<br>

##### Resumen de las funciones principales
```r
# Eliminar los NA de la base de datos
lista_variables <- c("var1","var2","var3"...)
datos_reg <- datos[lista_variables]
datos_reg <- na.omit(datos_Reg)

# Funci√≥n de la regresi√≥n
regresi√≥n <- lm(var1~var2 + var3 + var4, datos_reg) #Librer√≠a e1071
summary(regresi√≥n)

#Visualizar los coeficientes
coefplot(regresi√≥n, xlim=c(-5, 5), col.pts="blue", intercept=TRUE, main="Coeficientes de la regresi√≥n") #Librer√≠a arm

# Comprobaci√≥n de los supuestos principales
plot(regresi√≥n,2) #Normalidad de los residuos
bptest(regresi√≥n) #Homocedasticidad (librer√≠a lmtest)
vif(regresi√≥n) #Multicolinealidad (librer√≠a rms)

# Valores predichos


#Exportar los resultados
stargazer(regresi√≥n, type="text") #Librer√≠a stargazer

#Comparaci√≥n de modelos
AIC(modelo1, modelo2, modelo3)
BIC(modelo1, modelo2, modelo3)
```
<br>

##### Ejemplo pr√°ctico 
Vamos a estimar la propensi√≥n de voto a un partido (variable escala) en funci√≥n de las siguientes variables: 

-   edad del entrevistado (variable continua)
-   sexo (variable dicot√≥mica)
-   nivel educativo (variable dicot√≥mica)
-   opini√≥n sobre la situaci√≥n econ√≥mica personal (variable dicot√≥mica)
-   opini√≥n sobre la situaci√≥n econ√≥mica en Espa√±a (variable dicot√≥mica)
-   recuerdo de voto (variable polit√≥mica) 
-   ideolog√≠a del entrevistado (variable escala)


Es posible que estas variables no configuren un buen modelo. Sin embargo, son un buen ejercicio porque nos permitir√° ver c√≥mo se interpretan los diferentes tipos de variables e identificar algunos problemas.

<br>

##### Preparar la base de datos {#eliminarNA}

La regresi√≥n lineal es "sensible" a la existencia de casos perdidos en las variables que se introducen en los modelos. Para evitar que diferentes modelos tengan diferentes n√∫mero de casos **(en cuyo caso no ser√≠an comparables)** creamos un nuevo data.frame que contenga √∫nicamente las columnas que vamos a usar para estimar los modelos, para eliminar de estos los casos perdidos. A continuaci√≥n, eliminamos todas las filas que continenen valores perdidos. Esto se hace usando la funciones `na.omit()` o `na.exclude()`. 

```{r message=F, warning=F}
myvars <- c("prop_psoe", "prop_pp", "edad", "hombre", "recuerdo19", "estudios_universitarios", "ideol", "ecoper", "ecoesp")   # nuevo data.frame
datos_red<-datos[myvars] #Los corchetes sirven para seleccionar solo el conjunto de datos especificado. Tambi√©n podr√≠a usarse la funci√≥n select.
datos_red<- na.omit(datos_red)
```
<br>

##### El modelo de regresi√≥n {#modeloreg}

A continuaci√≥n, esitmamos el modelo de regresi√≥n (modelPP) con las variables arriba especificadas. Usaremos la funci√≥n `lm()` de la liber√≠a _e1071_ (como ocurre siempre, existen muchas otras librer√≠as que incluyen funciones para estimar regresiones lineales y son igualmente v√°lidas). 

```{r message=FALSE, warning=FALSE}
library(e1071)

modelPP <- lm(prop_pp ~ edad + hombre + estudios_universitarios + ecoper + ecoesp + recuerdo19 + ideol, data=datos_red)  
summary(modelPP)
```

Como podemos observar, R transforma la variable polit√≥mica "recuerdo19" en c-1 variables. Lo hace porque est√° definida como factor, de lo contrario tratar√≠a la variable como num√©rica (lo cual no tendr√≠a ning√∫n sentido). En este caso, cada variable se interpreta __en relaci√≥n a la categor√≠a de refencia__ (en este caso, PSOE). La funci√≥n `relevel()` nos permite cambiar cambiar la categor√≠a de referencia. Por ejemplo, si queremos que "PP" sea nuestra categor√≠a de referencia, har√≠amos lo siguiente:

Lo √∫nico que cambia es la categor√≠a de referencia en la variable recuerdo19 y, por consiguiente, los coeficientes de las dummies. El resto de la tabla ser√° id√©ntica. 
```r
modelPP_newrc<- lm(prop_pp ~ edad + hombre + estudios_universitarios + ecoper + ecoesp +relevel(recuerdo19, ref ="PP") + ideol, data=datos_red) 
summary(modelPP_newrc)
```
<br>

**Significatividad del modelo**

Los resultados muestran que todas las variables menos edad y g√©nero son estad√≠sticamente significativas para un NC del 99.9%. Esto es as√≠ porque, dado que los p-valores son <0.001, podemos rechazar la hip√≥tesis nula con una probabilidad de equivocarnos inferior a 0.001. 
<br>

##### Interpretaci√≥n de los coeficientes {#coef}

M√°s all√° de la significaci√≥n estad√≠stica, es importante interpretar el tama√±o del coeficiente. En otras palabras, la magnitud del efecto. En regresi√≥n lineal m√∫ltiple, los coeficientes de regresi√≥n representan el __cambio promedio que se produce en la VD por cada unidad de cambio en la VI, mientras el resto de variables se mantiene constante__ (*ceteris paribus*). Este control estad√≠stico que proporciona la regresi√≥n es muy importante, porque aisla el efecto de una variable del resto de variable incluidas en el modelo.

El valor de los coeficientes se obtiene con la funci√≥n `sumary()` del modelo, y tambi√©n puede extraerse f√°cilmente de la lista _modelPP_ (ver funci√≥n `View(modelPP)`)

```{r}
modelPP$coefficients
```
Vamos  a ver algunos ejemplos: 

* El _coeficiente de estudios_universitarioscon_ES_ (0.1203) indica que, manteniendo constantes todas las dem√°s variables, tener estudios universitarios est√° asociado con un aumento de 0.1203 unidades en la propensi√≥n de voto al Partido Popular. En otras palabras, las personas con estudios universitarios tienen, en promedio, una mayor inclinaci√≥n a votar por el Partido Popular en comparaci√≥n con aquellas que no tienen estudios universitario (_ceteris paribus_)
* El _coeficiente de recuerdo19PP_ (4.149) indica que, manteniendo constantes todas las dem√°s variables, las personas que recuerdan haber votado al Partido Popular en las elecciones de 2019 tienen una propensi√≥n de voto al Partido Popular 4.149 unidades mayor en comparaci√≥n con aquellas que recuerdan haber votado al PSOE (la categor√≠a de referencia). Esto significa que, en t√©rminos de propensi√≥n al voto, el recuerdo de haber votado al PP en el pasado est√° fuertemente asociado con una mayor inclinaci√≥n a votar nuevamente por este partido, mucho m√°s que en comparaci√≥n con aquellos que votaron al PSOE (_ceteris paribus_)

<br>

**Visualizacion de los coeficientes**

Una manera r√°pida de presentar los resultados de la regresi√≥n es representar gr√°ficamente los coeficientes. Para ello, podemos usar la funci√≥n `coefplot()`
```{r message=F, warning=F}
p_load(arm)
coefplot(modelPP, xlim=c(-5, 5),col.pts="blue", intercept=TRUE, main="Coeficientes de la regresi√≥n")
```

Este tipo de gr√°fico es particularmente √∫til cuando quereos coparar los coeficientes de dos o m√°s. Por ejemplo, si calculamos el mismo modelo para estimar la propensi√≥n de voto al PSOE, podemos visualizar los coeficientes de ambos modelos de la siguiente manera

```{r fig1, fig.heigh=3, fig.with=5, message=F, warning=FALSE}
#Estimamos el modelo
modelPSOE <- lm(prop_psoe ~ edad + hombre + estudios_universitarios + ecoper + ecoesp + recuerdo19 + ideol, data=datos_red)   

#Representamos gr√°ficamente los coeficientes de ambas regresiones (argumento add=T)
par(mfrow = c(1,1))
coefplot(modelPP, xlim=c(-5, 5),col.pts="blue", intercept=TRUE, main="Coeficientes")
coefplot(modelPSOE, add=TRUE, col.pts="red",  intercept=TRUE, offset=0.2, main="PSOE") 

#A√±adimos leyenda
legend("topright",  
       c("Propensi√≥n voto PP", "Propensi√≥n voto PSOE"), 
       lty = c(1,1),       
       col=c("blue","red"),
       cex = 0.7)
```
<br>

**¬øQu√© variable es la m√°s importante?**

Dado que las variables est√°n expresadas en diferentes unidades, los coeficientes de la regresi√≥n no son directamente comparables entre s√≠. Para hacer esto posible, es necesario transformar dichos coeficientes en coeficientes estandarizados (coeficientes Beta). Los coeficientes estandarizados se basan en puntuaciones t√≠picas y, por lo tanto, son comparables entre s√≠. 

```{r message=F, warning=FALSE}
p_load(lm.beta)
betaPP<-lm.beta(modelPP)
summary(betaPP)
```

Los coeficientes estandarizados representan la cantidad de cambio, en unidades de desviaci√≥n est√°ndar, que se producir√° en la variable dependiente por cada aumento de una unidad de desviaci√≥n est√°ndar en la correspondiente variable independiente (manteniendo constantes las dem√°s variables). Al estandarizar las variables, la constante se iguala a 0, por lo que no se incluye en la ecuaci√≥n de predicci√≥n. Estos coeficientes indican la importancia relativa de cada variable independiente en la ecuaci√≥n de regresi√≥n. En general, cuanto mayor es el valor absoluto del coeficiente de regresi√≥n estandarizado, mayor es el peso de la variable en la ecuaci√≥n de regresi√≥n.


**Bondad de ajuste del modelo** 
El R^2^ tiene un valor de 0.5873, lo que indica que nuestro modelo explica el 58.73% de varianza de la VD. En este caso, el valor de  R^2^ ajustado es pr√°cticamente id√©ntico.
<br>

##### Diagn√≥stico de la regresi√≥n {#supuestoS}
Vamos  a comprobar los supuestos de la regresi√≥n

1. *Normalidad de los residuos*. El test de normalidad que usamos en el ejemplo de regresi√≥n simple (_Shapiro test_) est√° limitado a n=5000. Dado que no tenemos esa opci√≥n, vamos a revisar el supuesto de normalidad un gr√°fico Q-Q: 

```{r message=F, warning=F, fig.height = 5, fig.width = 5, fig.align = "center"}
plot(modelPP, 2)
```
Comprobamos tambi√©n que la media de los residuos=0 
```{r message=F, warning=F}
mean(modelPP$residuals)
```

2. *Homocedasticidad* (varianza constante de los residuos)
  + Test de homocedasticidad
```{r message=F, warning=F}
#install.packages("lmtest")
library(lmtest)
het.lm<-bptest(modelPP)
het.lm
```

La hip√≥tesis nula en este test es que la varianza de los residuos es constante (homoced√°stica). La evidencia permite rechazar la hip√≥tesis nula, confirmando que la distribuci√≥n es heteroced√°stica. 

  + Gr√°ficamente: 
```{r}
plot( modelPP, 3)
```

3. *Multicolinealidad*. 
```{r message=F, warning=F}
reg.lineal.vif <- car::vif(modelPP)
reg.lineal.vif
```

No parece que existan problemas de multicolinealidad en nuestro modelo.
<br>

##### Valores predichos {#predichos} 

Al igual que hicimos con los coeficientes, una vez calculado el modelo podemos extraer los valores predichos (estimados) para cada individuo en la muestra consultando `modelPP$fitted.values`. Esto nos permite, por ejemplo, calcular el valor medio de propensi√≥n de voto al PP:

```{r echo=TRUE, message=FALSE, warning=FALSE}
mean(modelPP$fitted.values)
```

Tambi√©n podemos estimar qu√© valor tendr√° la variable dependiente para determinados valores de las variables independientes. Por ejemplo, vamos a calcular la propensi√≥n de voto al PP de un var√≥n de 50 a√±os, sin estudios universitarios (0), que valora positivamente su situaci√≥n econ√≥mica personal (1) pero no la situaci√≥n econ√≥mica del pa√≠s (0), con ideolog√≠a 5 y que en las elecciones de 2019 vot√≥ a C`s. 

```{r}
data1 <- data.frame(hombre="Hombre", edad=50, estudios_universitarios="con EU", ecoper="positiva", ecoesp="negativa", ideol=5, recuerdo19="Ciudadanos")
yhat1<-predict(modelPP, newdata = data1)
yhat1
```

O calcular, por ejemplo, c√≥mo cambia la propensi√≥n de voto al PP para un individuo con esas mismas caracter√≠sticas en funci√≥n de su edad:

```{r}
data2<- data.frame(hombre="Hombre", edad=c(20, 30, 40, 50, 60, 70, 80), estudios_universitarios="con EU", ecoper="positiva", ecoesp="negativa", ideol=5, recuerdo19="Ciudadanos")
yhat2<-predict(modelPP, newdata = data2)
yhat2
```
<br>

**Intervalos de confianza**

Los intervalos de confianza reflejan la incertidumbre alrededor de las estimaciones medias. Siguiendo con el ejemplo anterior, vamos a calcular las probabilides predichas con sus intervalos de confianza para todos los individuos en la muestra:

```{r}
yhat<-predict(modelPP, newdata = datos_red, interval = "confidence")
head(yhat) #visualizamos los 5 primeros casos
```

Si no queremos ver los casos perdidos usamos el argumento _na.action_ para especificarlo

```{r}
yhat<-predict(modelPP, newdata = datos_red, interval = "confidence", na.action=na.exclude)
head(yhat)
```

El _output_ contiene 3 columnas:

* FIT: el valor predicho (que tambi√©n hab√≠amos consultado a trav√©s de `modelPP$fitted.values`)
* LWR: l√≠mite inferior de la banda de confianza
* UPR: l√≠mite superior de la banda de confianza

Por defecto, R produce bandas de confianza al 95%,  pero esto se puede cambiar con el argumento _level_
```{r}
yhat<-predict(modelPP, newdata = datos_red, interval = "confidence", na.action=na.exclude, level=0.99)
head(yhat)
```
<br>

##### Exportar resultados {#Exportar}
Vamos a exportar a formato cient√≠fico los dos modelos que hemos estimado: modelPP y modelPSOE

1. Librer√≠a stargazer
```{r message=F, warning=F}
#install.packages("stargazer")
library(stargazer)
stargazer(modelPP, modelPSOE,      #Incluir aqu√≠ M1, M2, M3...
          type="text",
          dep.var.labels=c("Propensi√≥n voto PP", "Propensi√≥n voto PSOE"),
          covariate.labels=c("Edad", "Hombre", "Estudios superiores", "Economia personal: positiva (cr:neg)", "Economia pa√≠s: positiva (cr:neg)", "Voto 2019:PP (cr: PSOE)", "Voto 2019:VOX (cr: PSOE)", "Voto 2019:Podemos (cr: PSOE)", "Voto 2019:C¬¥s (cr: PSOE)", "Voto 2019:M√°s Madrid (cr: PSOE)", "Voto 2019:Otros (cr: PSOE)", "Voto 2019:Blanco (cr: PSOE)", "Ideolog√≠a", "Constante"))
```

2. Librer√≠a jtools. Est√° disponible √∫nicamente para un tipo de modelos muy limitado, pero OLS y GLM est√°n incluidos.

Instalamos los paquetes que van a hacernos falta 
```{r message=F, warning=FALSE}
#install.packages("jtools")
#install.packages("ggstance")
#install.packages("huxtable")
library(jtools)
library(ggstance)
library(huxtable)
```

La funci√≥n `summ()` muestra los resultados de la regresi√≥n
```{r message=F, warning=FALSE}
summ(modelPP)
```

La representaci√≥n gr√°fica de los coeficientes tambi√©n se hace de manera muy sencilla y muy parecida a la que ya conocemos
```{r}
plot_summs(modelPP)
```
Se pueden a√±adir tantos modelos como deseemos
```{r}
plot_summs(modelPP, modelPSOE)
```

Tambi√©n permite visualizar de manera r√°pida el efecto de una variable sobre la variable dependiente, siempre que la primera sea continua. Por ejemplo, vamos c√≥mo var√≠a la propensi√≥n de votar al PP con la ideolog√≠a, controlado por el resto de variables

```{r}
effect_plot(modelPP, pred = ideol, interval = TRUE)
```

Finalmente, la funci√≥n export_summs de jtools permite representar las tablas en formato "cient√≠fico".
```{r}
export_summs(modelPP, modelPSOE)

```

Para renombrar los modelos y las variables, usaremos los argumentos model.names y coefs de la siguiente manera

```{r}
export_summs(modelPP, modelPSOE, 
  model.names=c("Prop. Voto PP", 
                "Prop. Voto PSOE"), 
  coefs=c("Edad"="edad", 
          "Hombre"="hombreHombre", 
          "Estudios Universitarios"="estudios_universitarioscon EU", 
          "Econom√≠a personal positiva (cr=neg)"="ecoperpositiva", 
          "Econom√≠a pa√≠s positiva (cr=neg)"="ecoesppositiva", 
          "Voto 2019:PP (cr=PSOE)"="recuerdo19PP",
          "Voto 2019:VOX (cr=PSOE)"="recuerdo19VOX",
          "Voto 2019:Podemos (cr=PSOE)"="recuerdo19Podemos",
          "Voto 2019:C¬¥s (cr=PSOE)"="recuerdo19Ciudadanos",
          "Voto 2019:Mas Pa√≠s (cr=PSOE)"="recuerdo19M√°s Madrid",
          "Voto 2019:Otros (cr=PSOE)"="recuerdo19Otros",
          "Voto 2019:Blanco (cr=PSOE)"="recuerdo19En blanco",
          "Ideolog√≠a"="ideol",
          "Constante"="(Intercept)"
))
```
<br>

##### Comparaci√≥n de modelos {#cpmparar_modelos}

Es muy frecuente tener que elegir entre diferentes modelos. Hasta ahora, nos hemos fijado en el R^2^ para ver cu√°l era la bondad de ajuste del modelo. Aqu√≠, vamos a introducir dos nuevos indicadores: __BIC__ (Criterio de Informaci√≥n Bayesiano) y __AIC__ (Criterio de Informaci√≥n de Akaike). 

Cuando introducimos nuevas variables en el modelo aumentamos el ajuste, pero corremos el peligro de caer en sobreajuste. BIC y AIC resuelven este problema mediante la introducci√≥n de un t√©rmino de penalizaci√≥n para el n√∫mero de par√°metros en el modelo (esta penalizaci√≥n es mayor en el BIC que en el AIC). As√≠, dados dos modelos estimados, el modelo con el menor valor de BIC/AIC es preferible. Existe tambi√©n el AIC corregido (AICc), que es una variante del AIC para muestras reducidas (pocos datos).

Estimamos los modelos con el dataset reducido. El modelo1 incluye s√≥lamente la variable ideolog√≠a. El modelo2 a√±ade el sexo y el nivel educativo. El modelo3 es el full-model, que incluye la edad y la situaci√≥n laboral del entrevistado.

```{r}
modelo1 <- lm(prop_pp ~ hombre+estudios_universitarios, datos_red) 
modelo2 <- lm(prop_pp ~ hombre+estudios_universitarios+ ideol, datos_red)  
modelo3 <- lm(prop_pp ~ hombre+estudios_universitarios+ideol+recuerdo19, datos_red)  
```
Visualizamos los 3 modelos en una misma tabla
```{r message=F, warning=F}
library(stargazer)
stargazer(modelo1, modelo2, modelo3,    
          type="text",
          dep.var.labels=c("M1", "M2", "M3"),
          covariate.labels=c("Edad", "Hombre", "Estudios superiores", "Economia personal: positiva (cr:neg)", "Economia pa√≠s: positiva (cr:neg)", "Voto 2019:PP (cr: PSOE)", "Voto 2019:VOX (cr: PSOE)", "Voto 2019:Podemos (cr: PSOE)", "Voto 2019:C¬¥s (cr: PSOE)", "Voto 2019:M√°s Madrid (cr: PSOE)", "Voto 2019:Otros (cr: PSOE)", "Voto 2019:Blanco (cr: PSOE)", "Ideolog√≠a", "Constante"))
```

Y calculamos los BIC/AIC
```{r message=F, warning=F}
AIC(modelo1, modelo2, modelo3)
BIC(modelo1, modelo2, modelo3)
```
Diferencias m√°s notables:

  *   R^2^ ajustado es una medida de la varianza explicada en la variable de respuesta por los predictores, mientras que BIC/AIC son una compensaci√≥n entre la bondad del ajuste y la complejidad del modelo. 
  *   R^2^ puede subir o bajar seg√∫n se agregue o no otra variable al modelo. Pero el AIC/BIC no necesariamente cambian con la adici√≥n de una variable, sino que cambia con la composici√≥n de los predictores. 
  *   Otra ventaja adicional es que AIC/BIC permiten comparar entre modelos que no est√°n anidados. 

***
## Otras cosas

- [Secuencias de n√∫meros](#secuencia)
- [Valores perdidos](#NA)
- [Funciones](#funciones)
- [Recomendaciones para las variables dicot√≥micas](#recomendaciones_dicotomicas)

<br>

#### Crear una secuencia de n√∫meros:{#secuencia}
```{r}
secuencia<-5:15
secuencia
seq(5.5, 10, by = 0.5) #la secuencia ir√° de 5,5 hasta 10, de 0,5 en 0,5
seq(5, 10, length.out = 5) #entre el 5 y el 10, sacar√° una secuencia formada por 5 n√∫meros
```
Tambi√©n se pueden repetir valores:
```{r}
valores <- c("yes", "no")

rep(valores, times=3) #Repite la secuencia completa tres veces
rep(valores, each=3) #Repite cada uno de los valores del vector 3 veces
```

<br>

#### Valores perdidos{#NA}

Comprobar si hay valores perdidos: `is.na()` o `anyNA()`. En la consola dir√° True o False

<br>

#### Crear funciones{#funciones}
Permiten concentrar varios comandos en uno solo.

```r
nombre_funci√≥n <- function (x){
  argumentos de la funci√≥n
}
```
<br>

**Ejemplos:**

- Funci√≥n que devuelve el valor de la mitad de un n√∫mero:
```r
funcionmitad <- function(x){
  y <- x/2
  return(y)
}
```

- Funci√≥n que hace una potencia y a√±ade texto:
```r
funcionpotencia <- function(x,y){
  potencia <- x^y
  z <- "El resultado de la potencia es: "
  texto <- paste0(z,potencia)
  return(texto)
}
```
- Funci√≥n para crear tablas de frecuencia (como %) autom√°ticas (*funci√≥n table de stata*):
```r
tabla <- function(x,y){
  tabla_decimal <- table(x,y) %>% prop.table %>% round(4)
  tabla_porcentaje <- tabla_decimal*100
  return(tabla_porcentaje)
}
```

Si algunas de las funciones creadas se quiere reutilizar habitualmente, existen dos formas f√°ciles de volver a instalarlas:

1. Escribiendo estas funciones en un script a parte y usando `source`.
2. Crear un paquete propio.

<br>

#### Recomendaciones para las variables dicot√≥micas{#recomendaciones_dicotomicas}

Es recomendable nombrar a la variable como la categor√≠a de referencia. Por ejemplo, en el siguente ejemplo la variable se llama hombre en lugar de sexo porque el 1 se corresponde con los hombres. Es mejor hacerlo de este modo porque facilita la interpretaci√≥n de los an√°lisis. Por ejemplo, al hacer un summary de la nueva variable, se puede ver f√°cilmente que el 0.51 indica que la proporci√≥n de hombres en la muestra es del 51%.
```r
datos <- datos %>% 
  mutate(hombre=ifelse(SEXO==1, 1, 0))
```


***






